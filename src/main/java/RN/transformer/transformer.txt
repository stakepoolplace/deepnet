22:57:23.649 [main] INFO org.nd4j.linalg.factory.Nd4jBackend - Loaded [CpuBackend] backend
22:57:24.213 [main] INFO org.nd4j.nativeblas.NativeOpsHolder - Number of threads used for linear algebra: 1
22:57:24.216 [main] INFO org.nd4j.linalg.cpu.nativecpu.CpuNDArrayFactory - Binary level Generic x86 optimization level Generic x86
22:57:24.252 [main] INFO org.nd4j.nativeblas.Nd4jBlas - Number of threads used for OpenMP BLAS: 8
22:57:24.478 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Backend used: [CPU]; OS: [Mac OS X]
22:57:24.478 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Cores: [8]; Memory: [2,0GB];
22:57:24.478 [main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Blas vendor: [OPENBLAS]
22:57:24.481 [main] INFO org.nd4j.linalg.cpu.nativecpu.CpuBackend - Backend build information:
 Clang: "12.0.0 (clang-1200.0.32.29)"
STD version: 201103L
DEFAULT_ENGINE: samediff::ENGINE_CPU
HAVE_FLATBUFFERS
HAVE_OPENBLAS
22:57:24.500 [main] INFO org.deeplearning4j.models.sequencevectors.SequenceVectors - Starting vocabulary building...
22:57:24.501 [main] DEBUG org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Target vocab size before building: [0]
22:57:24.507 [main] DEBUG org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Trying source iterator: [0]
22:57:24.507 [main] DEBUG org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Target vocab size before building: [0]
22:57:24.512 [main] DEBUG org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Waiting till all processes stop...
22:57:24.515 [main] DEBUG org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Vocab size before truncation: [43],  NumWords: [93], sequences parsed: [14], counter: [86]
22:57:24.515 [main] DEBUG org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Scavenger: Words before: 43; Words after: 43;
22:57:24.516 [main] DEBUG org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Vocab size after truncation: [43],  NumWords: [93], sequences parsed: [14], counter: [86]
22:57:24.530 [main] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [14], Current vocabulary size: [43]; Sequences/sec: [482,76];
22:57:24.537 [main] INFO org.deeplearning4j.models.embeddings.loader.WordVectorSerializer - Projected memory use for model: [0,02 MB]
22:57:24.565 [main] INFO org.deeplearning4j.models.embeddings.inmemory.InMemoryLookupTable - Initializing syn1...
22:57:24.566 [main] INFO org.deeplearning4j.models.sequencevectors.SequenceVectors - Building learning algorithms:
22:57:24.567 [main] INFO org.deeplearning4j.models.sequencevectors.SequenceVectors -           building ElementsLearningAlgorithm: [SkipGram]
22:57:24.570 [main] INFO org.deeplearning4j.models.sequencevectors.SequenceVectors - Starting learning process...
22:57:24.617 [main] INFO org.deeplearning4j.models.sequencevectors.SequenceVectors - Epoch [1] finished; Elements processed so far: [860];  Sequences processed: [140]
22:57:24.617 [main] INFO org.deeplearning4j.models.sequencevectors.SequenceVectors - Time spent on training: 46 ms
22:57:24.621 [main] DEBUG org.deeplearning4j.models.embeddings.loader.WordVectorSerializer - Saving header: 43 50 14
Embedding pour le token 'mauvais' initialisé avec WordVectors.
Embedding pour le token 'aujourd'hui' initialisé avec WordVectors.
Embedding pour le token 'aiment' initialisé avec WordVectors.
Embedding pour le token 'est' initialisé avec WordVectors.
Embedding pour le token 'agréable' initialisé avec WordVectors.
Embedding pour le token 'journée' initialisé avec WordVectors.
Embedding pour le token 'temps' initialisé avec WordVectors.
Embedding pour le token 'sol' initialisé avec WordVectors.
Embedding pour le token 'sur' initialisé avec WordVectors.
Embedding pour le token 'mange' initialisé avec WordVectors.
Embedding pour le token 'belle' initialisé avec WordVectors.
Embedding pour le token 'un' initialisé avec WordVectors.
Embedding pour le token 'les' initialisé avec WordVectors.
Embedding pour le token 'chiens' initialisé avec WordVectors.
Embedding pour le token 'tapis' initialisé avec WordVectors.
Embedding pour le token 'intéressant' initialisé avec WordVectors.
Embedding pour le token 'ce' initialisé avec WordVectors.
Embedding pour le token 'jardin' initialisé avec WordVectors.
Embedding pour le token 'pas' initialisé avec WordVectors.
Embedding pour le token 'c'est' initialisé avec WordVectors.
Embedding pour le token 'excellent' initialisé avec WordVectors.
Embedding pour le token 'heureux' initialisé avec WordVectors.
Embedding pour le token 'fantastique' initialisé avec WordVectors.
Embedding pour le token 'film' initialisé avec WordVectors.
Embedding pour le token 'dans' initialisé avec WordVectors.
Embedding pour le token 'court' initialisé avec WordVectors.
Embedding pour le token 'chien' initialisé avec WordVectors.
Embedding pour le token 'livre' initialisé avec WordVectors.
Embedding pour le token 'n'aime' initialisé avec WordVectors.
Embedding pour le token 'triste' initialisé avec WordVectors.
Embedding pour le token 'souris' initialisé avec WordVectors.
Embedding pour le token 'déteste' initialisé avec WordVectors.
Embedding pour le token 'la' initialisé avec WordVectors.
Embedding pour le token 'chat' initialisé avec WordVectors.
Embedding pour le token 'quelle' initialisé avec WordVectors.
Embedding pour le token 'chats' initialisé avec WordVectors.
Embedding pour le token 'repas' initialisé avec WordVectors.
Embedding pour le token 'le' initialisé avec WordVectors.
Embedding pour le token 'suis' initialisé avec WordVectors.
Embedding pour le token 'je' initialisé avec WordVectors.
Embedding pour le token 'très' initialisé avec WordVectors.
Embedding pour le token 'mauvais' initialisé avec WordVectors.
Embedding pour le token 'aujourd'hui' initialisé avec WordVectors.
Embedding pour le token 'aiment' initialisé avec WordVectors.
Embedding pour le token 'est' initialisé avec WordVectors.
Embedding pour le token 'agréable' initialisé avec WordVectors.
Embedding pour le token 'journée' initialisé avec WordVectors.
Embedding pour le token 'temps' initialisé avec WordVectors.
Embedding pour le token 'sol' initialisé avec WordVectors.
Embedding pour le token 'sur' initialisé avec WordVectors.
Embedding pour le token 'mange' initialisé avec WordVectors.
Embedding pour le token 'belle' initialisé avec WordVectors.
Embedding pour le token 'un' initialisé avec WordVectors.
Embedding pour le token 'les' initialisé avec WordVectors.
Embedding pour le token 'chiens' initialisé avec WordVectors.
Embedding pour le token 'tapis' initialisé avec WordVectors.
Embedding pour le token 'intéressant' initialisé avec WordVectors.
Embedding pour le token 'ce' initialisé avec WordVectors.
Embedding pour le token 'jardin' initialisé avec WordVectors.
Embedding pour le token 'pas' initialisé avec WordVectors.
Embedding pour le token 'c'est' initialisé avec WordVectors.
Embedding pour le token 'excellent' initialisé avec WordVectors.
Embedding pour le token 'heureux' initialisé avec WordVectors.
Embedding pour le token 'fantastique' initialisé avec WordVectors.
Embedding pour le token 'film' initialisé avec WordVectors.
Embedding pour le token 'dans' initialisé avec WordVectors.
Embedding pour le token 'court' initialisé avec WordVectors.
Embedding pour le token 'chien' initialisé avec WordVectors.
Embedding pour le token 'livre' initialisé avec WordVectors.
Embedding pour le token 'n'aime' initialisé avec WordVectors.
Embedding pour le token 'triste' initialisé avec WordVectors.
Embedding pour le token 'souris' initialisé avec WordVectors.
Embedding pour le token 'déteste' initialisé avec WordVectors.
Embedding pour le token 'la' initialisé avec WordVectors.
Embedding pour le token 'chat' initialisé avec WordVectors.
Embedding pour le token 'quelle' initialisé avec WordVectors.
Embedding pour le token 'chats' initialisé avec WordVectors.
Embedding pour le token 'repas' initialisé avec WordVectors.
Embedding pour le token 'le' initialisé avec WordVectors.
Embedding pour le token 'suis' initialisé avec WordVectors.
Embedding pour le token 'je' initialisé avec WordVectors.
Embedding pour le token 'très' initialisé avec WordVectors.
Vocabulaire du Tokenizer:
Token: '<PAD>' -> ID: 0
Token: '<UNK>' -> ID: 1
Token: '<START>' -> ID: 2
Token: '<END>' -> ID: 3
Token: 'mauvais' -> ID: 4
Token: 'aujourd'hui' -> ID: 5
Token: 'aiment' -> ID: 6
Token: 'est' -> ID: 7
Token: 'agréable' -> ID: 8
Token: 'journée' -> ID: 9
Token: 'temps' -> ID: 10
Token: 'sol' -> ID: 11
Token: 'sur' -> ID: 12
Token: 'mange' -> ID: 13
Token: 'belle' -> ID: 14
Token: 'un' -> ID: 15
Token: 'les' -> ID: 16
Token: 'chiens' -> ID: 17
Token: 'tapis' -> ID: 18
Token: 'intéressant' -> ID: 19
Token: 'ce' -> ID: 20
Token: 'jardin' -> ID: 21
Token: 'pas' -> ID: 22
Token: 'c'est' -> ID: 23
Token: 'excellent' -> ID: 24
Token: 'heureux' -> ID: 25
Token: 'fantastique' -> ID: 26
Token: 'film' -> ID: 27
Token: 'dans' -> ID: 28
Token: 'court' -> ID: 29
Token: 'chien' -> ID: 30
Token: 'livre' -> ID: 31
Token: 'n'aime' -> ID: 32
Token: 'triste' -> ID: 33
Token: 'souris' -> ID: 34
Token: 'déteste' -> ID: 35
Token: 'la' -> ID: 36
Token: 'chat' -> ID: 37
Token: 'quelle' -> ID: 38
Token: 'chats' -> ID: 39
Token: 'repas' -> ID: 40
Token: 'le' -> ID: 41
Token: 'suis' -> ID: 42
Token: 'je' -> ID: 43
Token: 'très' -> ID: 44
22:57:24.776 [main] DEBUG org.deeplearning4j.models.embeddings.loader.WordVectorSerializer - Trying full model restoration...
22:57:24.779 [main] DEBUG org.deeplearning4j.models.embeddings.loader.WordVectorSerializer - Trying CSV model restoration...
22:57:24.779 [main] DEBUG org.deeplearning4j.models.embeddings.loader.WordVectorSerializer - First line is a header
Token ID 0 embedding was frozen.
Token ID 2 embedding was frozen.
Token ID 3 embedding was frozen.
<UNK> embedding has calculated values. Skipping freezing.
Texte: 'chat mange la souris'
Tokens: [<START>, chat, mange, la, souris, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 37, 13, 36, 34, 3, 0, 0, 0]
Texte: 'chien court dans le jardin'
Tokens: [<START>, chien, court, dans, le, jardin, <END>, <PAD>, <PAD>]
IDs: [2, 30, 29, 28, 41, 21, 3, 0, 0]
Texte: 'les chats aiment les chiens'
Tokens: [<START>, les, chats, aiment, les, chiens, <END>, <PAD>, <PAD>]
IDs: [2, 16, 39, 6, 16, 17, 3, 0, 0]
Texte: 'tapis sur le sol'
Tokens: [<START>, tapis, sur, le, sol, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 18, 12, 41, 11, 3, 0, 0, 0]
Texte: 'ce film est fantastique'
Tokens: [<START>, ce, film, est, fantastique, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 20, 27, 7, 26, 3, 0, 0, 0]
Texte: 'je déteste ce temps'
Tokens: [<START>, je, déteste, ce, temps, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 43, 35, 20, 10, 3, 0, 0, 0]
Texte: 'quelle belle journée'
Tokens: [<START>, quelle, belle, journée, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 38, 14, 9, 3, 0, 0, 0, 0]
Texte: 'le chat sol'
Tokens: [<START>, le, chat, sol, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 37, 11, 3, 0, 0, 0, 0]
Texte: 'c'est un mauvais film'
Tokens: [<START>, c, ', est, un, mauvais, film, <END>, <PAD>]
IDs: [2, 1, 1, 7, 15, 4, 27, 3, 0]
Texte: 'ce livre est intéressant'
Tokens: [<START>, ce, livre, est, intéressant, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 20, 31, 7, 19, 3, 0, 0, 0]
Texte: 'je n'aime pas ce repas'
Tokens: [<START>, je, n, ', aime, pas, ce, repas, <END>]
IDs: [2, 43, 1, 1, 1, 22, 20, 40, 3]
Texte: 'ce film est excellent'
Tokens: [<START>, ce, film, est, excellent, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 20, 27, 7, 24, 3, 0, 0, 0]
Texte: 'je suis triste aujourd'hui'
Tokens: [<START>, je, suis, triste, aujourd, ', hui, <END>, <PAD>]
IDs: [2, 43, 42, 33, 1, 1, 1, 3, 0]
Texte: 'ce temps est agréable'
Tokens: [<START>, ce, temps, est, agréable, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 20, 10, 7, 8, 3, 0, 0, 0]
Texte: 'le chat mange'
Tokens: [<START>, le, chat, mange, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 37, 13, 3, 0, 0, 0, 0]
Texte: 'le chien court'
Tokens: [<START>, le, chien, court, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 30, 29, 3, 0, 0, 0, 0]
Texte: 'les chats aiment'
Tokens: [<START>, les, chats, aiment, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 16, 39, 6, 3, 0, 0, 0, 0]
Texte: 'le tapis sur'
Tokens: [<START>, le, tapis, sur, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 18, 12, 3, 0, 0, 0, 0]
Texte: 'le film est fantastique'
Tokens: [<START>, le, film, est, fantastique, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 27, 7, 26, 3, 0, 0, 0]
Texte: 'je déteste'
Tokens: [<START>, je, déteste, <END>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 43, 35, 3, 0, 0, 0, 0, 0]
Texte: 'quelle belle'
Tokens: [<START>, quelle, belle, <END>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 38, 14, 3, 0, 0, 0, 0, 0]
Texte: 'le chat'
Tokens: [<START>, le, chat, <END>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 37, 3, 0, 0, 0, 0, 0]
Texte: 'c'est un mauvais'
Tokens: [<START>, c, ', est, un, mauvais, <END>, <PAD>, <PAD>]
IDs: [2, 1, 1, 7, 15, 4, 3, 0, 0]
Texte: 'le livre est intéressant'
Tokens: [<START>, le, livre, est, intéressant, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 31, 7, 19, 3, 0, 0, 0]
Texte: 'je n'aime pas'
Tokens: [<START>, je, n, ', aime, pas, <END>, <PAD>, <PAD>]
IDs: [2, 43, 1, 1, 1, 22, 3, 0, 0]
Texte: 'le film est excellent'
Tokens: [<START>, le, film, est, excellent, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 27, 7, 24, 3, 0, 0, 0]
Texte: 'je suis triste'
Tokens: [<START>, je, suis, triste, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 43, 42, 33, 3, 0, 0, 0, 0]
Texte: 'le temps est agréable'
Tokens: [<START>, le, temps, est, agréable, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 10, 7, 8, 3, 0, 0, 0]
Texte: 'chat manger la souris'
Tokens: [<START>, chat, manger, la, souris, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 37, 1, 36, 34, 3, 0]
Texte: 'chiens aiment le jardin'
Tokens: [<START>, chiens, aiment, le, jardin, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 17, 6, 41, 21, 3, 0]
Texte: 'chat aiment les chiens'
Tokens: [<START>, chat, aiment, les, chiens, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 37, 6, 16, 17, 3, 0]
Texte: 'chat sur le tapis'
Tokens: [<START>, chat, sur, le, tapis, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 37, 12, 41, 18, 3, 0]
Texte: 'ce livre est intéressant'
Tokens: [<START>, ce, livre, est, intéressant, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 20, 31, 7, 19, 3, 0]
Texte: 'je n'aime pas ce repas'
Tokens: [<START>, je, n, ', aime, pas, ce, repas, <END>]
IDs: [2, 43, 1, 1, 1, 22, 20]
Texte: 'ce film est excellent'
Tokens: [<START>, ce, film, est, excellent, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 20, 27, 7, 24, 3, 0]
Texte: 'je suis triste aujourd'hui'
Tokens: [<START>, je, suis, triste, aujourd, ', hui, <END>, <PAD>]
IDs: [2, 43, 42, 33, 1, 1, 1]
Texte: 'ce temps est agréable'
Tokens: [<START>, ce, temps, est, agréable, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 20, 10, 7, 8, 3, 0]
Texte: 'quelle belle journée'
Tokens: [<START>, quelle, belle, journée, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 38, 14, 9, 3, 0, 0]
Texte: 'le chat manger'
Tokens: [<START>, le, chat, manger, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 37, 1, 3, 0, 0]
Texte: 'les chiens aiment'
Tokens: [<START>, les, chiens, aiment, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 16, 17, 6, 3, 0, 0]
Texte: 'le chat aiment'
Tokens: [<START>, le, chat, aiment, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 37, 6, 3, 0, 0]
Texte: 'le chat sur'
Tokens: [<START>, le, chat, sur, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 37, 12, 3, 0, 0]
Texte: 'le livre est intéressant'
Tokens: [<START>, le, livre, est, intéressant, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 31, 7, 19, 3, 0]
Texte: 'je n'aime pas'
Tokens: [<START>, je, n, ', aime, pas, <END>, <PAD>, <PAD>]
IDs: [2, 43, 1, 1, 1, 22, 3]
Texte: 'le film est excellent'
Tokens: [<START>, le, film, est, excellent, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 27, 7, 24, 3, 0]
Texte: 'je suis triste'
Tokens: [<START>, je, suis, triste, <END>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 43, 42, 33, 3, 0, 0]
Texte: 'le temps est agréable'
Tokens: [<START>, le, temps, est, agréable, <END>, <PAD>, <PAD>, <PAD>]
IDs: [2, 41, 10, 7, 8, 3, 0]
Texte: 'quelle belle'
Tokens: [<START>, quelle, belle, <END>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]
IDs: [2, 38, 14, 3, 0, 0, 0]
Epoch 1
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1277         0,1343         0,1522         0,1769         0,1987         0,2102         0,0000
chat           0,1313         0,1371         0,1534         0,1761         0,1960         0,2061         0,0000
<UNK>          0,1331         0,1393         0,1550         0,1759         0,1935         0,2031         0,0000
la             0,1314         0,1397         0,1563         0,1768         0,1928         0,2029         0,0000
souris         0,1288         0,1389         0,1567         0,1779         0,1933         0,2044         0,0000
<END>          0,1269         0,1373         0,1558         0,1786         0,1951         0,2063         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           <UNK>          <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4940         0,5060         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3300         0,3451         0,3249         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2558         0,2732         0,2565         0,2145         0,0000         0,0000         0,0000
<END>          0,2173         0,2352         0,2225         0,1844         0,1406         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2122         0,1758         0,1608         0,1551         0,1533         0,1428         0,0000
le             0,2143         0,1836         0,1663         0,1544         0,1459         0,1354         0,0000
chat           0,2147         0,1896         0,1716         0,1544         0,1404         0,1293         0,0000
<UNK>          0,2123         0,1925         0,1765         0,1556         0,1377         0,1254         0,0000
<END>          0,2088         0,1930         0,1799         0,1571         0,1374         0,1238         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1276         0,1339         0,1518         0,1767         0,2000         0,2101         0,0000
chiens         0,1315         0,1369         0,1532         0,1759         0,1970         0,2055         0,0000
aiment         0,1331         0,1388         0,1544         0,1757         0,1950         0,2029         0,0000
le             0,1309         0,1389         0,1555         0,1767         0,1951         0,2030         0,0000
jardin         0,1280         0,1380         0,1558         0,1777         0,1961         0,2043         0,0000
<END>          0,1267         0,1367         0,1550         0,1780         0,1978         0,2059         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        les            chiens         aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
les            0,4946         0,5054         0,0000         0,0000         0,0000         0,0000         0,0000
chiens         0,3298         0,3450         0,3252         0,0000         0,0000         0,0000         0,0000
aiment         0,2570         0,2742         0,2569         0,2119         0,0000         0,0000         0,0000
<END>          0,2169         0,2356         0,2230         0,1823         0,1422         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
-
-
-
-
-
-
------------------------------------------------------------------------------------------------------------------
<START>        0,2132         0,1758         0,1604         0,1548         0,1524         0,1435         0,0000
les            0,2154         0,1840         0,1657         0,1540         0,1449         0,1360         0,0000
chiens         0,2163         0,1900         0,1706         0,1536         0,1394         0,1301         0,0000
aiment         0,2134         0,1925         0,1757         0,1551         0,1371         0,1264         0,0000
<END>          0,2104         0,1932         0,1795         0,1563         0,1363         0,1242         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 4.4383335
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1234         0,1289         0,1476         0,1762         0,2051         0,2188         0,0000
chat           0,1271         0,1316         0,1489         0,1755         0,2023         0,2145         0,0000
aiment         0,1292         0,1342         0,1506         0,1753         0,1997         0,2110         0,0000
les            0,1273         0,1347         0,1521         0,1763         0,1991         0,2105         0,0000
chiens         0,1252         0,1345         0,1528         0,1771         0,1994         0,2110         0,0000
<END>          0,1239         0,1333         0,1521         0,1774         0,2009         0,2123         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4862         0,5138         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3322         0,3574         0,3105         0,0000         0,0000         0,0000         0,0000
aiment         0,2725         0,2956         0,2538         0,1781         0,0000         0,0000         0,0000
<END>          0,2401         0,2645         0,2288         0,1583         0,1083         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2015         0,1600         0,1464         0,1568         0,1700         0,1653         0,0000
le             0,2005         0,1648         0,1507         0,1577         0,1656         0,1607         0,0000
chat           0,1992         0,1690         0,1555         0,1587         0,1617         0,1559         0,0000
aiment         0,1963         0,1709         0,1601         0,1605         0,1599         0,1523         0,0000
<END>          0,1948         0,1722         0,1635         0,1614         0,1585         0,1496         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1232         0,1287         0,1471         0,1769         0,2056         0,2185         0,0000
chat           0,1268         0,1314         0,1486         0,1762         0,2028         0,2142         0,0000
sur            0,1290         0,1340         0,1506         0,1760         0,1999         0,2105         0,0000
le             0,1274         0,1346         0,1520         0,1770         0,1992         0,2100         0,0000
tapis          0,1249         0,1341         0,1526         0,1780         0,1995         0,2109         0,0000
<END>          0,1237         0,1332         0,1518         0,1783         0,2009         0,2121         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           sur            <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4860         0,5140         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3331         0,3579         0,3090         0,0000         0,0000         0,0000         0,0000
sur            0,2719         0,2960         0,2532         0,1788         0,0000         0,0000         0,0000
<END>          0,2401         0,2647         0,2279         0,1594         0,1079         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2017         0,1599         0,1472         0,1550         0,1704         0,1658         0,0000
le             0,2005         0,1646         0,1518         0,1559         0,1661         0,1610         0,0000
chat           0,1991         0,1687         0,1568         0,1569         0,1624         0,1561         0,0000
sur            0,1963         0,1704         0,1611         0,1587         0,1607         0,1527         0,0000
<END>          0,1945         0,1718         0,1646         0,1598         0,1594         0,1498         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 4.1429377
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1231         0,1275         0,1477         0,1764         0,2056         0,2197         0,0000
ce             0,1271         0,1305         0,1493         0,1759         0,2024         0,2148         0,0000
livre          0,1285         0,1322         0,1504         0,1760         0,2006         0,2124         0,0000
est            0,1278         0,1337         0,1523         0,1768         0,1989         0,2105         0,0000
intéressant    0,1252         0,1334         0,1529         0,1777         0,1994         0,2114         0,0000
<END>          0,1238         0,1321         0,1520         0,1780         0,2010         0,2131         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4873         0,5127         0,0000         0,0000         0,0000         0,0000         0,0000
livre          0,3340         0,3556         0,3104         0,0000         0,0000         0,0000         0,0000
est            0,2717         0,2948         0,2538         0,1796         0,0000         0,0000         0,0000
intéressant    0,2410         0,2663         0,2282         0,1597         0,1049         0,0000         0,0000
<END>          0,2142         0,2413         0,2090         0,1474         0,0970         0,0911         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1997         0,1571         0,1460         0,1563         0,1722         0,1688         0,0000
le             0,1975         0,1619         0,1506         0,1577         0,1682         0,1641         0,0000
livre          0,1963         0,1658         0,1550         0,1588         0,1646         0,1595         0,0000
est            0,1939         0,1678         0,1595         0,1606         0,1626         0,1556         0,0000
intéressant    0,1922         0,1689         0,1629         0,1618         0,1614         0,1528         0,0000
<END>          0,1920         0,1707         0,1655         0,1623         0,1595         0,1500         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1015         0,1049         0,1217         0,1460         0,1697         0,1815         0,1747
je             0,1054         0,1079         0,1235         0,1461         0,1679         0,1782         0,1708
<UNK>          0,1069         0,1100         0,1251         0,1463         0,1664         0,1759         0,1694
<UNK>          0,1058         0,1107         0,1263         0,1467         0,1656         0,1746         0,1704
<UNK>          0,1035         0,1102         0,1267         0,1472         0,1656         0,1747         0,1721
pas            0,1025         0,1094         0,1262         0,1475         0,1667         0,1756         0,1720
ce             0,1030         0,1084         0,1249         0,1477         0,1687         0,1773         0,1701

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            <END>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4834         0,5166         0,0000         0,0000         0,0000         0,0000         0,0000
<UNK>          0,3300         0,3581         0,3119         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2708         0,2976         0,2553         0,1762         0,0000         0,0000         0,0000
<UNK>          0,2402         0,2674         0,2294         0,1570         0,1060         0,0000         0,0000
pas            0,2136         0,2421         0,2104         0,1445         0,0978         0,0915         0,0000
<END>          0,1829         0,2146         0,1908         0,1301         0,0852         0,0782         0,1182

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1756         0,1368         0,1255         0,1353         0,1526         0,1502         0,1240
je             0,1750         0,1411         0,1295         0,1356         0,1479         0,1451         0,1258
<UNK>          0,1730         0,1442         0,1337         0,1368         0,1450         0,1411         0,1261
<UNK>          0,1707         0,1458         0,1378         0,1390         0,1442         0,1386         0,1239
<UNK>          0,1696         0,1469         0,1410         0,1406         0,1437         0,1368         0,1214
pas            0,1691         0,1487         0,1438         0,1417         0,1426         0,1346         0,1195
<END>          0,1720         0,1531         0,1466         0,1411         0,1389         0,1303         0,1180

Perte pour ce batch: 4.2199464
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1224         0,1267         0,1482         0,1762         0,2060         0,2205         0,0000
ce             0,1264         0,1297         0,1501         0,1757         0,2028         0,2155         0,0000
film           0,1281         0,1317         0,1517         0,1757         0,2006         0,2122         0,0000
est            0,1272         0,1330         0,1534         0,1764         0,1994         0,2107         0,0000
excellent      0,1245         0,1324         0,1539         0,1772         0,2002         0,2118         0,0000
<END>          0,1233         0,1314         0,1532         0,1776         0,2015         0,2131         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4867         0,5133         0,0000         0,0000         0,0000         0,0000         0,0000
film           0,3341         0,3575         0,3084         0,0000         0,0000         0,0000         0,0000
est            0,2741         0,2979         0,2537         0,1743         0,0000         0,0000         0,0000
excellent      0,2438         0,2699         0,2295         0,1561         0,1007         0,0000         0,0000
<END>          0,2181         0,2461         0,2116         0,1444         0,0931         0,0868         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1961         0,1540         0,1422         0,1567         0,1770         0,1740         0,0000
le             0,1936         0,1584         0,1471         0,1583         0,1730         0,1696         0,0000
film           0,1924         0,1624         0,1519         0,1597         0,1690         0,1646         0,0000
est            0,1896         0,1639         0,1558         0,1617         0,1676         0,1613         0,0000
excellent      0,1888         0,1649         0,1585         0,1627         0,1664         0,1587         0,0000
<END>          0,1881         0,1668         0,1614         0,1636         0,1645         0,1556         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1009         0,1042         0,1207         0,1463         0,1702         0,1817         0,1759
je             0,1048         0,1073         0,1224         0,1464         0,1683         0,1784         0,1723
suis           0,1061         0,1090         0,1239         0,1464         0,1670         0,1765         0,1712
triste         0,1052         0,1100         0,1257         0,1467         0,1657         0,1750         0,1717
<UNK>          0,1031         0,1097         0,1264         0,1470         0,1657         0,1752         0,1731
<UNK>          0,1020         0,1088         0,1258         0,1473         0,1668         0,1763         0,1730
<UNK>          0,1026         0,1078         0,1241         0,1476         0,1689         0,1779         0,1710

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4828         0,5172         0,0000         0,0000         0,0000         0,0000         0,0000
suis           0,3294         0,3583         0,3122         0,0000         0,0000         0,0000         0,0000
triste         0,2737         0,3006         0,2575         0,1682         0,0000         0,0000         0,0000
<END>          0,2435         0,2714         0,2329         0,1511         0,1011         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1725         0,1339         0,1235         0,1354         0,1554         0,1531         0,1262
je             0,1715         0,1379         0,1276         0,1356         0,1511         0,1484         0,1278
suis           0,1694         0,1408         0,1318         0,1369         0,1484         0,1448         0,1281
triste         0,1670         0,1422         0,1358         0,1391         0,1476         0,1422         0,1261
<END>          0,1657         0,1431         0,1388         0,1408         0,1473         0,1406         0,1237
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 3.8011534
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1216         0,1257         0,1463         0,1763         0,2080         0,2221         0,0000
ce             0,1256         0,1287         0,1483         0,1758         0,2046         0,2171         0,0000
temps          0,1274         0,1308         0,1498         0,1757         0,2024         0,2138         0,0000
est            0,1266         0,1323         0,1519         0,1765         0,2009         0,2119         0,0000
agréable       0,1241         0,1319         0,1524         0,1773         0,2015         0,2128         0,0000
<END>          0,1228         0,1308         0,1517         0,1777         0,2029         0,2141         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4858         0,5142         0,0000         0,0000         0,0000         0,0000         0,0000
temps          0,3347         0,3591         0,3062         0,0000         0,0000         0,0000         0,0000
est            0,2768         0,3017         0,2543         0,1671         0,0000         0,0000         0,0000
agréable       0,2486         0,2751         0,2318         0,1511         0,0934         0,0000         0,0000
<END>          0,2233         0,2526         0,2153         0,1405         0,0868         0,0815         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1948         0,1523         0,1410         0,1559         0,1788         0,1772         0,0000
le             0,1918         0,1562         0,1454         0,1576         0,1756         0,1734         0,0000
temps          0,1897         0,1596         0,1498         0,1593         0,1725         0,1692         0,0000
est            0,1876         0,1613         0,1538         0,1612         0,1707         0,1655         0,0000
agréable       0,1864         0,1620         0,1567         0,1625         0,1696         0,1628         0,0000
<END>          0,1862         0,1639         0,1593         0,1631         0,1677         0,1598         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1554         0,1627         0,1877         0,2286         0,2656         0,0000         0,0000
quelle         0,1597         0,1659         0,1883         0,2261         0,2601         0,0000         0,0000
belle          0,1613         0,1685         0,1899         0,2249         0,2555         0,0000         0,0000
journée        0,1596         0,1694         0,1919         0,2254         0,2538         0,0000         0,0000
<END>          0,1568         0,1689         0,1932         0,2268         0,2543         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          <END>          <PAD>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
quelle         0,4830         0,5170         0,0000         0,0000         0,0000         0,0000         0,0000
belle          0,3343         0,3628         0,3029         0,0000         0,0000         0,0000         0,0000
<END>          0,2767         0,3061         0,2532         0,1639         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2328         0,1885         0,1749         0,1896         0,2141         0,0000         0,0000
quelle         0,2287         0,1917         0,1791         0,1909         0,2095         0,0000         0,0000
belle          0,2252         0,1949         0,1839         0,1919         0,2042         0,0000         0,0000
<END>          0,2213         0,1964         0,1879         0,1933         0,2010         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 3.814605
Epoch 1 completed with average loss: 0.024219427
Epoch 1 Loss: 0.024219427
Epoch 2
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1208         0,1256         0,1453         0,1771         0,2076         0,2235         0,0000
chat           0,1247         0,1286         0,1469         0,1764         0,2046         0,2189         0,0000
<UNK>          0,1271         0,1315         0,1490         0,1763         0,2014         0,2147         0,0000
la             0,1261         0,1328         0,1509         0,1773         0,1998         0,2131         0,0000
souris         0,1243         0,1330         0,1520         0,1782         0,1993         0,2132         0,0000
<END>          0,1226         0,1316         0,1512         0,1789         0,2010         0,2148         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           <UNK>          <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4824         0,5176         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3363         0,3661         0,2976         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2816         0,3102         0,2498         0,1584         0,0000         0,0000         0,0000
<END>          0,2551         0,2839         0,2296         0,1450         0,0863         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1959         0,1514         0,1380         0,1529         0,1804         0,1814         0,0000
le             0,1930         0,1544         0,1418         0,1547         0,1779         0,1782         0,0000
chat           0,1896         0,1571         0,1463         0,1569         0,1756         0,1745         0,0000
<UNK>          0,1874         0,1586         0,1501         0,1589         0,1741         0,1709         0,0000
<END>          0,1857         0,1593         0,1528         0,1603         0,1734         0,1685         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
--------
--------
--------------------------------------------------------------------------------------------------------
<START>        0,1207         0,1251         0,1448         0,1768         0,2093         0,2233         0,0000
chiens         0,1249         0,1284         0,1464         0,1761         0,2060         0,2183         0,0000
aiment         0,1270         0,1309         0,1482         0,1760         0,2033         0,2145         0,0000
le             0,1257         0,1318         0,1499         0,1769         0,2024         0,2131         0,0000
jardin         0,1236         0,1319         0,1510         0,1779         0,2025         0,2131         0,0000
<END>          0,1223         0,1308         0,1504         0,1782         0,2040         0,2144         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        les            chiens         aiment         <END>          <PAD>          <PAD>
---------
---------
------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
les            0,4839         0,5161         0,0000         0,0000         0,0000         0,0000         0,0000
chiens         0,3367         0,3652         0,2981         0,0000         0,0000         0,0000         0,0000
aiment         0,2829         0,3102         0,2502         0,1567         0,0000         0,0000         0,0000
<END>          0,2549         0,2837         0,2302         0,1435         0,0878         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1961         0,1513         0,1376         0,1531         0,1802         0,1818         0,0000
les            0,1934         0,1546         0,1413         0,1548         0,1774         0,1785         0,0000
chiens         0,1905         0,1573         0,1454         0,1566         0,1751         0,1751         0,0000
aiment         0,1880         0,1585         0,1493         0,1586         0,1739         0,1717         0,0000
<END>          0,1869         0,1594         0,1525         0,1599         0,1727         0,1687         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 3.6149642
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1204         0,1248         0,1442         0,1761         0,2093         0,2252         0,0000
chat           0,1243         0,1279         0,1457         0,1754         0,2062         0,2203         0,0000
aiment         0,1270         0,1311         0,1479         0,1752         0,2029         0,2159         0,0000
les            0,1256         0,1322         0,1499         0,1762         0,2017         0,2143         0,0000
chiens         0,1239         0,1325         0,1510         0,1771         0,2015         0,2140         0,0000
<END>          0,1226         0,1314         0,1504         0,1774         0,2029         0,2152         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4815         0,5185         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3386         0,3698         0,2915         0,0000         0,0000         0,0000         0,0000
aiment         0,2885         0,3174         0,2475         0,1466         0,0000         0,0000         0,0000
<END>          0,2617         0,2921         0,2296         0,1353         0,0812         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1987         0,1516         0,1355         0,1519         0,1799         0,1825         0,0000
le             0,1953         0,1542         0,1387         0,1535         0,1780         0,1802         0,0000
chat           0,1918         0,1566         0,1427         0,1555         0,1762         0,1772         0,0000
aiment         0,1892         0,1577         0,1464         0,1575         0,1752         0,1740         0,0000
<END>          0,1880         0,1586         0,1493         0,1586         0,1742         0,1714         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1202         0,1247         0,1437         0,1767         0,2099         0,2249         0,0000
chat           0,1241         0,1277         0,1455         0,1761         0,2067         0,2199         0,0000
sur            0,1268         0,1309         0,1478         0,1759         0,2032         0,2153         0,0000
le             0,1257         0,1320         0,1497         0,1769         0,2018         0,2138         0,0000
tapis          0,1236         0,1322         0,1508         0,1780         0,2016         0,2139         0,0000
<END>          0,1225         0,1313         0,1501         0,1783         0,2029         0,2149         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           sur            <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4811         0,5189         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3393         0,3705         0,2902         0,0000         0,0000         0,0000         0,0000
sur            0,2876         0,3177         0,2468         0,1478         0,0000         0,0000         0,0000
<END>          0,2614         0,2923         0,2287         0,1367         0,0808         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1991         0,1517         0,1358         0,1506         0,1799         0,1829         0,0000
le             0,1956         0,1542         0,1393         0,1522         0,1781         0,1806         0,0000
chat           0,1920         0,1564         0,1434         0,1543         0,1764         0,1774         0,0000
sur            0,1894         0,1574         0,1470         0,1562         0,1756         0,1744         0,0000
<END>          0,1879         0,1583         0,1500         0,1575         0,1746         0,1716         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 3.5919743
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1201         0,1231         0,1438         0,1760         0,2103         0,2266         0,0000
ce             0,1246         0,1265         0,1458         0,1755         0,2065         0,2210         0,0000
livre          0,1266         0,1290         0,1475         0,1756         0,2039         0,2173         0,0000
est            0,1268         0,1314         0,1501         0,1764         0,2013         0,2140         0,0000
intéressant    0,1245         0,1316         0,1513         0,1774         0,2012         0,2140         0,0000
<END>          0,1232         0,1305         0,1505         0,1776         0,2026         0,2154         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4812         0,5188         0,0000         0,0000         0,0000         0,0000         0,0000
livre          0,3413         0,3713         0,2874         0,0000         0,0000         0,0000         0,0000
est            0,2905         0,3214         0,2459         0,1422         0,0000         0,0000         0,0000
intéressant    0,2658         0,2993         0,2287         0,1323         0,0739         0,0000         0,0000
<END>          0,2438         0,2797         0,2157         0,1257         0,0704         0,0646         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2033         0,1523         0,1348         0,1487         0,1773         0,1837         0,0000
le             0,1984         0,1544         0,1379         0,1508         0,1764         0,1822         0,0000
livre          0,1946         0,1562         0,1413         0,1529         0,1753         0,1797         0,0000
est            0,1919         0,1569         0,1446         0,1551         0,1746         0,1770         0,0000
intéressant    0,1904         0,1572         0,1471         0,1566         0,1741         0,1746         0,0000
<END>          0,1905         0,1585         0,1490         0,1572         0,1727         0,1722         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,0987         0,1010         0,1181         0,1452         0,1731         0,1865         0,1774
je             0,1030         0,1044         0,1203         0,1454         0,1709         0,1827         0,1732
<UNK>          0,1052         0,1071         0,1224         0,1457         0,1689         0,1795         0,1712
<UNK>          0,1046         0,1086         0,1243         0,1463         0,1674         0,1772         0,1715
<UNK>          0,1028         0,1088         0,1252         0,1469         0,1671         0,1765         0,1728
pas            0,1020         0,1082         0,1249         0,1472         0,1680         0,1771         0,1725
ce             0,1020         0,1068         0,1232         0,1473         0,1703         0,1794         0,1709

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            <END>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4787         0,5213         0,0000         0,0000         0,0000         0,0000         0,0000
<UNK>          0,3390         0,3731         0,2879         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2907         0,3237         0,2465         0,1391         0,0000         0,0000         0,0000
<UNK>          0,2662         0,3002         0,2292         0,1296         0,0748         0,0000         0,0000
pas            0,2443         0,2803         0,2164         0,1228         0,0710         0,0651         0,0000
<END>          0,2167         0,2567         0,2009         0,1117         0,0619         0,0556         0,0965

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
-
-
------
------
----------------------------------------------------------------------------------------------------------
<START>        0,1777         0,1312         0,1150         0,1271         0,1544         0,1603         0,1343
je             0,1743         0,1332         0,1178         0,1282         0,1524         0,1576         0,1366
<UNK>          0,1704         0,1343         0,1208         0,1300         0,1517         0,1557         0,1371
<UNK>          0,1676         0,1348         0,1238         0,1323         0,1519         0,1542         0,1354
<UNK>          0,1668         0,1353         0,1261         0,1339         0,1518         0,1528         0,1332
pas            0,1664         0,1363         0,1279         0,1348         0,1513         0,1514         0,1319
<END>          0,1680         0,1392         0,1296         0,1345         0,1490         0,1484         0,1312

Perte pour ce batch: 3.7381885
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1200         0,1225         0,1443         0,1757         0,2104         0,2271         0,0000
ce             0,1246         0,1261         0,1465         0,1752         0,2064         0,2212         0,0000
film           0,1272         0,1291         0,1489         0,1751         0,2032         0,2164         0,0000
est            0,1272         0,1314         0,1516         0,1758         0,2009         0,2131         0,0000
excellent      0,1249         0,1316         0,1527         0,1767         0,2010         0,2131         0,0000
<END>          0,1238         0,1308         0,1522         0,1771         0,2021         0,2141         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4802         0,5198         0,0000         0,0000         0,0000         0,0000         0,0000
film           0,3422         0,3742         0,2836         0,0000         0,0000         0,0000         0,0000
est            0,2938         0,3261         0,2447         0,1354         0,0000         0,0000         0,0000
excellent      0,2693         0,3044         0,2292         0,1275         0,0695         0,0000         0,0000
<END>          0,2489         0,2863         0,2174         0,1213         0,0661         0,0602         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2088         0,1553         0,1340         0,1460         0,1746         0,1813         0,0000
le             0,2033         0,1568         0,1369         0,1481         0,1742         0,1807         0,0000
film           0,1992         0,1583         0,1403         0,1503         0,1732         0,1786         0,0000
est            0,1960         0,1584         0,1429         0,1526         0,1733         0,1769         0,0000
excellent      0,1950         0,1584         0,1445         0,1539         0,1731         0,1751         0,0000
<END>          0,1945         0,1596         0,1465         0,1547         0,1719         0,1728         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,0986         0,1005         0,1172         0,1454         0,1734         0,1866         0,1783
je             0,1031         0,1041         0,1193         0,1455         0,1710         0,1826         0,1744
suis           0,1051         0,1067         0,1214         0,1456         0,1691         0,1796         0,1725
triste         0,1050         0,1087         0,1241         0,1461         0,1671         0,1770         0,1721
<UNK>          0,1033         0,1090         0,1254         0,1465         0,1665         0,1763         0,1729
<UNK>          0,1023         0,1083         0,1250         0,1469         0,1676         0,1772         0,1727
<UNK>          0,1025         0,1070         0,1229         0,1471         0,1700         0,1794         0,1711

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4789         0,5211         0,0000         0,0000         0,0000         0,0000         0,0000
suis           0,3408         0,3743         0,2849         0,0000         0,0000         0,0000         0,0000
triste         0,2953         0,3275         0,2462         0,1310         0,0000         0,0000         0,0000
<END>          0,2712         0,3052         0,2306         0,1233         0,0696         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1827         0,1343         0,1155         0,1250         0,1507         0,1568         0,1350
je             0,1788         0,1358         0,1180         0,1260         0,1494         0,1552         0,1370
suis           0,1745         0,1365         0,1207         0,1278         0,1491         0,1539         0,1374
triste         0,1717         0,1366         0,1234         0,1301         0,1495         0,1528         0,1360
<END>          0,1704         0,1366         0,1253         0,1317         0,1498         0,1519         0,1342
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 3.291192
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1196         0,1218         0,1425         0,1757         0,2120         0,2284         0,0000
ce             0,1244         0,1256         0,1450         0,1752         0,2078         0,2222         0,0000
temps          0,1272         0,1287         0,1474         0,1751         0,2044         0,2172         0,0000
est            0,1273         0,1314         0,1505         0,1759         0,2017         0,2132         0,0000
agréable       0,1253         0,1318         0,1517         0,1767         0,2016         0,2129         0,0000
<END>          0,1239         0,1309         0,1512         0,1772         0,2029         0,2140         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             temps          est            agréable       <END>          <PAD>
---------
---------
------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4808         0,5192         0,0000         0,0000         0,0000         0,0000         0,0000
temps          0,3438         0,3744         0,2818         0,0000         0,0000         0,0000         0,0000
est            0,2970         0,3286         0,2455         0,1289         0,0000         0,0000         0,0000
agréable       0,2737         0,3078         0,2312         0,1223         0,0651         0,0000         0,0000
<END>          0,2535         0,2907         0,2203         0,1168         0,0622         0,0565         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2161         0,1608         0,1372         0,1432         0,1673         0,1755         0,0000
le             0,2102         0,1617         0,1395         0,1452         0,1677         0,1756         0,0000
temps          0,2057         0,1626         0,1423         0,1474         0,1676         0,1744         0,0000
est            0,2027         0,1626         0,1448         0,1494         0,1676         0,1728         0,0000
agréable       0,2015         0,1623         0,1466         0,1507         0,1676         0,1713         0,0000
<END>          0,2012         0,1634         0,1481         0,1513         0,1666         0,1694         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1540         0,1590         0,1841         0,2296         0,2733         0,0000         0,0000
quelle         0,1591         0,1629         0,1851         0,2267         0,2663         0,0000         0,0000
belle          0,1616         0,1666         0,1875         0,2249         0,2594         0,0000         0,0000
journée        0,1606         0,1686         0,1903         0,2251         0,2555         0,0000         0,0000
<END>          0,1582         0,1689         0,1922         0,2261         0,2546         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          <END>          <PAD>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
quelle         0,4747         0,5253         0,0000         0,0000         0,0000         0,0000         0,0000
belle          0,3418         0,3815         0,2767         0,0000         0,0000         0,0000         0,0000
<END>          0,2955         0,3353         0,2424         0,1268         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2579         0,1959         0,1674         0,1741         0,2046         0,0000         0,0000
quelle         0,2516         0,1965         0,1701         0,1768         0,2050         0,0000         0,0000
belle          0,2454         0,1971         0,1735         0,1795         0,2044         0,0000         0,0000
<END>          0,2412         0,1971         0,1761         0,1817         0,2039         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 3.2685332
Epoch 2 completed with average loss: 0.020764949
Epoch 2 Loss: 0.020764949
Epoch 3
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1188         0,1216         0,1413         0,1763         0,2119         0,2301         0,0000
chat           0,1234         0,1253         0,1434         0,1756         0,2080         0,2242         0,0000
<UNK>          0,1268         0,1294         0,1465         0,1757         0,2036         0,2181         0,0000
la             0,1266         0,1318         0,1495         0,1769         0,2008         0,2145         0,0000
souris         0,1253         0,1329         0,1513         0,1780         0,1994         0,2131         0,0000
<END>          0,1236         0,1317         0,1507         0,1787         0,2009         0,2145         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           <UNK>          <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4801         0,5199         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3470         0,3786         0,2743         0,0000         0,0000         0,0000         0,0000
<UNK>          0,3017         0,3339         0,2407         0,1237         0,0000         0,0000         0,0000
<END>          0,2787         0,3128         0,2276         0,1184         0,0624         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2238         0,1680         0,1393         0,1399         0,1605         0,1685         0,0000
le             0,2182         0,1682         0,1412         0,1419         0,1613         0,1692         0,0000
chat           0,2130         0,1684         0,1437         0,1442         0,1619         0,1688         0,0000
<UNK>          0,2097         0,1682         0,1459         0,1460         0,1623         0,1678         0,0000
<END>          0,2083         0,1678         0,1472         0,1471         0,1625         0,1670         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
-----
-----
-
-
------------------------------------------------------------------------------------------------------------
<START>        0,1187         0,1209         0,1405         0,1759         0,2140         0,2300         0,0000
chiens         0,1238         0,1250         0,1428         0,1752         0,2097         0,2236         0,0000
aiment         0,1268         0,1287         0,1455         0,1751         0,2058         0,2180         0,0000
le             0,1263         0,1307         0,1483         0,1762         0,2038         0,2147         0,0000
jardin         0,1247         0,1316         0,1502         0,1773         0,2030         0,2132         0,0000
<END>          0,1234         0,1306         0,1498         0,1777         0,2043         0,2142         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        les            chiens         aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
les            0,4829         0,5171         0,0000         0,0000         0,0000         0,0000         0,0000
chiens         0,3479         0,3760         0,2761         0,0000         0,0000         0,0000         0,0000
aiment         0,3028         0,3316         0,2419         0,1237         0,0000         0,0000         0,0000
<END>          0,2787         0,3107         0,2291         0,1184         0,0632         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2236         0,1682         0,1389         0,1403         0,1606         0,1684         0,0000
les            0,2180         0,1685         0,1407         0,1423         0,1614         0,1690         0,0000
chiens         0,2133         0,1688         0,1430         0,1443         0,1619         0,1688         0,0000
aiment         0,2100         0,1684         0,1453         0,1461         0,1623         0,1679         0,0000
<END>          0,2088         0,1681         0,1468         0,1471         0,1624         0,1668         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 3.014874
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1199         0,1222         0,1407         0,1753         0,2122         0,2297         0,0000
chat           0,1248         0,1262         0,1429         0,1746         0,2082         0,2234         0,0000
aiment         0,1284         0,1306         0,1461         0,1745         0,2035         0,2169         0,0000
les            0,1276         0,1328         0,1492         0,1757         0,2012         0,2135         0,0000
chiens         0,1262         0,1339         0,1511         0,1768         0,2001         0,2119         0,0000
<END>          0,1249         0,1329         0,1506         0,1772         0,2015         0,2129         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4827         0,5173         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3498         0,3775         0,2728         0,0000         0,0000         0,0000         0,0000
aiment         0,3057         0,3341         0,2403         0,1199         0,0000         0,0000         0,0000
<END>          0,2818         0,3136         0,2279         0,1145         0,0622         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2270         0,1727         0,1418         0,1397         0,1566         0,1622         0,0000
le             0,2214         0,1724         0,1432         0,1415         0,1578         0,1636         0,0000
chat           0,2166         0,1723         0,1452         0,1434         0,1587         0,1639         0,0000
aiment         0,2133         0,1719         0,1472         0,1450         0,1592         0,1634         0,0000
<END>          0,2122         0,1716         0,1484         0,1458         0,1594         0,1626         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1197         0,1221         0,1403         0,1755         0,2129         0,2295         0,0000
chat           0,1246         0,1260         0,1427         0,1748         0,2087         0,2231         0,0000
sur            0,1284         0,1305         0,1462         0,1747         0,2039         0,2164         0,0000
le             0,1278         0,1327         0,1490         0,1759         0,2015         0,2132         0,0000
tapis          0,1260         0,1336         0,1509         0,1772         0,2005         0,2118         0,0000
<END>          0,1248         0,1328         0,1504         0,1776         0,2017         0,2127         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           sur            <END>          <PAD>          <PAD>
------------------------------
------------------------------
------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4823         0,5177         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3499         0,3777         0,2724         0,0000         0,0000         0,0000         0,0000
sur            0,3045         0,3339         0,2400         0,1216         0,0000         0,0000         0,0000
<END>          0,2811         0,3133         0,2274         0,1163         0,0620         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2275         0,1730         0,1418         0,1393         0,1559         0,1625         0,0000
le             0,2218         0,1726         0,1432         0,1412         0,1573         0,1639         0,0000
chat           0,2168         0,1723         0,1453         0,1431         0,1583         0,1641         0,0000
sur            0,2136         0,1719         0,1473         0,1447         0,1589         0,1636         0,0000
<END>          0,2124         0,1717         0,1486         0,1455         0,1590         0,1628         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.8301086
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1217         0,1225         0,1424         0,1749         0,2107         0,2277         0,0000
ce             0,1274         0,1271         0,1451         0,1743         0,2058         0,2204         0,0000
livre          0,1303         0,1307         0,1479         0,1744         0,2019         0,2148         0,0000
est            0,1310         0,1342         0,1515         0,1752         0,1982         0,2097         0,0000
intéressant    0,1286         0,1348         0,1532         0,1764         0,1979         0,2091         0,0000
<END>          0,1272         0,1337         0,1526         0,1769         0,1993         0,2104         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4854         0,5146         0,0000         0,0000         0,0000         0,0000         0,0000
livre          0,3518         0,3746         0,2737         0,0000         0,0000         0,0000         0,0000
est            0,3052         0,3311         0,2405         0,1232         0,0000         0,0000         0,0000
intéressant    0,2815         0,3117         0,2273         0,1174         0,0621         0,0000         0,0000
<END>          0,2623         0,2950         0,2166         0,1126         0,0596         0,0538         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2257         0,1731         0,1441         0,1402         0,1547         0,1622         0,0000
le             0,2194         0,1723         0,1453         0,1422         0,1566         0,1642         0,0000
livre          0,2148         0,1718         0,1469         0,1439         0,1578         0,1649         0,0000
est            0,2117         0,1711         0,1484         0,1455         0,1586         0,1647         0,0000
intéressant    0,2107         0,1706         0,1494         0,1463         0,1588         0,1641         0,0000
<END>          0,2109         0,1713         0,1504         0,1466         0,1581         0,1628         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1002         0,1006         0,1170         0,1447         0,1740         0,1872         0,1764
je             0,1056         0,1051         0,1200         0,1450         0,1709         0,1820         0,1714
<UNK>          0,1085         0,1088         0,1230         0,1456         0,1682         0,1775         0,1684
<UNK>          0,1084         0,1112         0,1258         0,1465         0,1662         0,1740         0,1679
<UNK>          0,1066         0,1120         0,1273         0,1473         0,1655         0,1726         0,1687
pas            0,1058         0,1116         0,1271         0,1477         0,1664         0,1731         0,1684
ce             0,1055         0,1097         0,1250         0,1477         0,1690         0,1760         0,1672

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            <END>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4863         0,5137         0,0000         0,0000         0,0000         0,0000         0,0000
<UNK>          0,3537         0,3754         0,2709         0,0000         0,0000         0,0000         0,0000
<UNK>          0,3082         0,3324         0,2384         0,1209         0,0000         0,0000         0,0000
<UNK>          0,2846         0,3124         0,2253         0,1153         0,0624         0,0000         0,0000
pas            0,2657         0,2958         0,2149         0,1103         0,0597         0,0537         0,0000
<END>          0,2452         0,2763         0,2011         0,1010         0,0529         0,0467         0,0767

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1971         0,1503         0,1240         0,1206         0,1345         0,1403         0,1332
je             0,1919         0,1496         0,1249         0,1219         0,1354         0,1411         0,1354
<UNK>          0,1873         0,1488         0,1262         0,1235         0,1364         0,1416         0,1362
<UNK>          0,1845         0,1480         0,1275         0,1250         0,1375         0,1419         0,1356
<UNK>          0,1839         0,1479         0,1285         0,1258         0,1378         0,1416         0,1346
pas            0,1837         0,1483         0,1293         0,1262         0,1376         0,1410         0,1340
<END>          0,1844         0,1502         0,1303         0,1260         0,1362         0,1392         0,1337

Perte pour ce batch: 3.405889
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1237         0,1242         0,1442         0,1745         0,2086         0,2248         0,0000
ce             0,1296         0,1290         0,1473         0,1737         0,2032         0,2170         0,0000
film           0,1331         0,1332         0,1507         0,1737         0,1988         0,2104         0,0000
est            0,1333         0,1364         0,1543         0,1745         0,1957         0,2058         0,0000
excellent      0,1306         0,1367         0,1558         0,1756         0,1958         0,2055         0,0000
<END>          0,1292         0,1358         0,1554         0,1762         0,1970         0,2065         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4850         0,5150         0,0000         0,0000         0,0000         0,0000         0,0000
film           0,3505         0,3743         0,2752         0,0000         0,0000         0,0000         0,0000
est            0,3035         0,3297         0,2413         0,1254         0,0000         0,0000         0,0000
excellent      0,2791         0,3099         0,2283         0,1196         0,0631         0,0000         0,0000
<END>          0,2605         0,2931         0,2172         0,1142         0,0603         0,0548         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2196         0,1719         0,1442         0,1420         0,1579         0,1644         0,0000
le             0,2134         0,1707         0,1452         0,1439         0,1600         0,1668         0,0000
film           0,2088         0,1699         0,1466         0,1456         0,1614         0,1677         0,0000
est            0,2057         0,1690         0,1477         0,1470         0,1626         0,1680         0,0000
excellent      0,2051         0,1685         0,1483         0,1476         0,1630         0,1675         0,0000
<END>          0,2051         0,1691         0,1492         0,1480         0,1623         0,1663         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1020         0,1021         0,1177         0,1450         0,1725         0,1850         0,1757
je             0,1077         0,1069         0,1207         0,1450         0,1692         0,1796         0,1709
suis           0,1105         0,1105         0,1238         0,1452         0,1665         0,1754         0,1681
triste         0,1106         0,1133         0,1271         0,1459         0,1641         0,1720         0,1670
<UNK>          0,1085         0,1139         0,1288         0,1467         0,1635         0,1710         0,1676
<UNK>          0,1073         0,1132         0,1284         0,1471         0,1646         0,1719         0,1675
<UNK>          0,1075         0,1115         0,1260         0,1472         0,1672         0,1744         0,1662

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4863         0,5137         0,0000         0,0000         0,0000         0,0000         0,0000
suis           0,3521         0,3740         0,2740         0,0000         0,0000         0,0000         0,0000
triste         0,3061         0,3300         0,2409         0,1230         0,0000         0,0000         0,0000
<END>          0,2822         0,3100         0,2277         0,1169         0,0632         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1914         0,1486         0,1246         0,1222         0,1359         0,1420         0,1353
je             0,1862         0,1474         0,1252         0,1233         0,1372         0,1433         0,1373
suis           0,1818         0,1465         0,1263         0,1248         0,1383         0,1441         0,1381
triste         0,1791         0,1455         0,1273         0,1262         0,1395         0,1446         0,1377
<END>          0,1783         0,1452         0,1281         0,1270         0,1400         0,1445         0,1369
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 3.109252
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1253         0,1256         0,1440         0,1744         0,2076         0,2231         0,0000
ce             0,1314         0,1306         0,1474         0,1736         0,2019         0,2150         0,0000
temps          0,1350         0,1348         0,1507         0,1735         0,1976         0,2085         0,0000
est            0,1351         0,1382         0,1545         0,1743         0,1944         0,2034         0,0000
agréable       0,1324         0,1385         0,1559         0,1755         0,1946         0,2031         0,0000
<END>          0,1307         0,1374         0,1554         0,1761         0,1960         0,2043         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4855         0,5145         0,0000         0,0000         0,0000         0,0000         0,0000
temps          0,3493         0,3722         0,2785         0,0000         0,0000         0,0000         0,0000
est            0,3019         0,3274         0,2444         0,1263         0,0000         0,0000         0,0000
agréable       0,2779         0,3076         0,2313         0,1200         0,0633         0,0000         0,0000
<END>          0,2587         0,2907         0,2203         0,1147         0,0607         0,0549         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2159         0,1721         0,1462         0,1433         0,1573         0,1652         0,0000
le             0,2099         0,1705         0,1470         0,1451         0,1597         0,1678         0,0000
temps          0,2052         0,1693         0,1480         0,1468         0,1615         0,1692         0,0000
est            0,2021         0,1683         0,1490         0,1482         0,1628         0,1697         0,0000
agréable       0,2012         0,1678         0,1496         0,1488         0,1633         0,1693         0,0000
<END>          0,2014         0,1684         0,1504         0,1490         0,1627         0,1682         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1602         0,1625         0,1843         0,2264         0,2667         0,0000         0,0000
quelle         0,1665         0,1676         0,1859         0,2227         0,2573         0,0000         0,0000
belle          0,1694         0,1722         0,1891         0,2206         0,2487         0,0000         0,0000
journée        0,1680         0,1747         0,1925         0,2207         0,2441         0,0000         0,0000
<END>          0,1650         0,1750         0,1949         0,2220         0,2431         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          <END>          <PAD>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
quelle         0,4779         0,5221         0,0000         0,0000         0,0000         0,0000         0,0000
belle          0,3453         0,3794         0,2752         0,0000         0,0000         0,0000         0,0000
<END>          0,2992         0,3348         0,2431         0,1230         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2560         0,2056         0,1751         0,1726         0,1907         0,0000         0,0000
quelle         0,2507         0,2042         0,1764         0,1752         0,1936         0,0000         0,0000
belle          0,2451         0,2027         0,1780         0,1779         0,1962         0,0000         0,0000
<END>          0,2414         0,2019         0,1796         0,1796         0,1975         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 3.1084998
Epoch 3 completed with average loss: 0.018349493
Epoch 3 Loss: 0.018349493
Epoch 4
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1263         0,1275         0,1442         0,1749         0,2056         0,2215         0,0000
chat           0,1322         0,1325         0,1471         0,1740         0,2004         0,2138         0,0000
<UNK>          0,1361         0,1375         0,1510         0,1741         0,1950         0,2062         0,0000
la             0,1356         0,1403         0,1545         0,1755         0,1919         0,2021         0,0000
souris         0,1337         0,1414         0,1566         0,1769         0,1907         0,2007         0,0000
<END>          0,1316         0,1399         0,1559         0,1778         0,1925         0,2023         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           <UNK>          <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4829         0,5171         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3488         0,3758         0,2754         0,0000         0,0000         0,0000         0,0000
<UNK>          0,3012         0,3302         0,2419         0,1267         0,0000         0,0000         0,0000
<END>          0,2774         0,3096         0,2288         0,1204         0,0638         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2116         0,1719         0,1462         0,1443         0,1592         0,1667         0,0000
le             0,2061         0,1701         0,1467         0,1461         0,1616         0,1693         0,0000
chat           0,2007         0,1683         0,1477         0,1481         0,1639         0,1712         0,0000
<UNK>          0,1975         0,1671         0,1484         0,1494         0,1656         0,1721         0,0000
<END>          0,1963         0,1666         0,1489         0,1499         0,1662         0,1721         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1264         0,1267         0,1432         0,1741         0,2080         0,2216         0,0000
chiens         0,1329         0,1322         0,1464         0,1732         0,2022         0,2132         0,0000
aiment         0,1364         0,1368         0,1500         0,1731         0,1974         0,2063         0,0000
le             0,1356         0,1390         0,1532         0,1744         0,1952         0,2026         0,0000
jardin         0,1332         0,1398         0,1554         0,1758         0,1946         0,2012         0,0000
<END>          0,1316         0,1386         0,1549         0,1763         0,1960         0,2024         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        les            chiens         aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
les            0,4852         0,5148         0,0000         0,0000         0,0000         0,0000         0,0000
chiens         0,3495         0,3733         0,2772         0,0000         0,0000         0,0000         0,0000
aiment         0,3015         0,3278         0,2430         0,1277         0,0000         0,0000         0,0000
<END>          0,2770         0,3075         0,2302         0,1213         0,0640         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2112         0,1726         0,1455         0,1452         0,1591         0,1664         0,0000
les            0,2057         0,1709         0,1460         0,1469         0,1614         0,1690         0,0000
chiens         0,2006         0,1692         0,1468         0,1487         0,1637         0,1711         0,0000
aiment         0,1975         0,1678         0,1475         0,1499         0,1653         0,1720         0,0000
<END>          0,1965         0,1673         0,1482         0,1503         0,1658         0,1719         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.760387
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1280         0,1291         0,1441         0,1741         0,2051         0,2196         0,0000
chat           0,1341         0,1343         0,1470         0,1731         0,1998         0,2117         0,0000
aiment         0,1382         0,1396         0,1510         0,1729         0,1942         0,2039         0,0000
les            0,1370         0,1419         0,1545         0,1744         0,1919         0,2004         0,0000
chiens         0,1349         0,1429         0,1566         0,1757         0,1910         0,1989         0,0000
<END>          0,1331         0,1416         0,1560         0,1762         0,1927         0,2003         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4822         0,5178         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3469         0,3750         0,2781         0,0000         0,0000         0,0000         0,0000
aiment         0,2994         0,3291         0,2439         0,1277         0,0000         0,0000         0,0000
<END>          0,2746         0,3082         0,2307         0,1208         0,0657         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2072         0,1705         0,1460         0,1465         0,1619         0,1679         0,0000
le             0,2018         0,1686         0,1463         0,1481         0,1644         0,1708         0,0000
chat           0,1963         0,1666         0,1470         0,1500         0,1670         0,1732         0,0000
aiment         0,1930         0,1651         0,1476         0,1511         0,1688         0,1744         0,0000
<END>          0,1916         0,1644         0,1480         0,1516         0,1697         0,1747         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1279         0,1290         0,1439         0,1738         0,2058         0,2195         0,0000
chat           0,1340         0,1342         0,1470         0,1728         0,2004         0,2115         0,0000
sur            0,1384         0,1396         0,1512         0,1727         0,1946         0,2035         0,0000
le             0,1372         0,1419         0,1544         0,1741         0,1922         0,2002         0,0000
tapis          0,1347         0,1427         0,1564         0,1756         0,1915         0,1990         0,0000
<END>          0,1331         0,1416         0,1558         0,1762         0,1930         0,2003         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           sur            <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4820         0,5180         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3468         0,3750         0,2781         0,0000         0,0000         0,0000         0,0000
sur            0,2983         0,3286         0,2437         0,1295         0,0000         0,0000         0,0000
<END>          0,2738         0,3077         0,2303         0,1226         0,0655         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2074         0,1707         0,1462         0,1465         0,1610         0,1681         0,0000
le             0,2020         0,1688         0,1466         0,1482         0,1636         0,1709         0,0000
chat           0,1965         0,1667         0,1473         0,1500         0,1663         0,1733         0,0000
sur            0,1930         0,1651         0,1478         0,1511         0,1683         0,1747         0,0000
<END>          0,1917         0,1645         0,1483         0,1516         0,1690         0,1748         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.6701066
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1298         0,1295         0,1467         0,1737         0,2031         0,2172         0,0000
ce             0,1366         0,1352         0,1502         0,1728         0,1969         0,2082         0,0000
livre          0,1398         0,1395         0,1536         0,1728         0,1925         0,2018         0,0000
est            0,1402         0,1433         0,1576         0,1736         0,1887         0,1966         0,0000
intéressant    0,1368         0,1433         0,1592         0,1751         0,1889         0,1967         0,0000
<END>          0,1350         0,1421         0,1585         0,1757         0,1906         0,1982         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4820         0,5180         0,0000         0,0000         0,0000         0,0000         0,0000
livre          0,3451         0,3732         0,2817         0,0000         0,0000         0,0000         0,0000
est            0,2955         0,3263         0,2455         0,1328         0,0000         0,0000         0,0000
intéressant    0,2701         0,3056         0,2314         0,1254         0,0675         0,0000         0,0000
<END>          0,2511         0,2881         0,2197         0,1196         0,0645         0,0570         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2030         0,1686         0,1467         0,1475         0,1628         0,1715         0,0000
le             0,1971         0,1665         0,1470         0,1492         0,1656         0,1747         0,0000
livre          0,1916         0,1642         0,1473         0,1510         0,1685         0,1774         0,0000
est            0,1879         0,1624         0,1475         0,1523         0,1708         0,1792         0,0000
intéressant    0,1864         0,1613         0,1477         0,1529         0,1719         0,1798         0,0000
<END>          0,1866         0,1618         0,1483         0,1530         0,1714         0,1789         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1077         0,1070         0,1213         0,1449         0,1691         0,1793         0,1708
je             0,1143         0,1126         0,1252         0,1452         0,1651         0,1728         0,1649
<UNK>          0,1176         0,1170         0,1288         0,1458         0,1620         0,1676         0,1613
<UNK>          0,1170         0,1196         0,1318         0,1469         0,1601         0,1641         0,1606
<UNK>          0,1144         0,1201         0,1333         0,1479         0,1597         0,1630         0,1615
pas            0,1133         0,1196         0,1330         0,1483         0,1607         0,1637         0,1614
ce             0,1131         0,1175         0,1307         0,1483         0,1634         0,1667         0,1604

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            <END>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4821         0,5179         0,0000         0,0000         0,0000         0,0000         0,0000
<UNK>          0,3463         0,3743         0,2794         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2974         0,3280         0,2440         0,1306         0,0000         0,0000         0,0000
<UNK>          0,2726         0,3070         0,2297         0,1232         0,0675         0,0000         0,0000
pas            0,2537         0,2896         0,2181         0,1172         0,0643         0,0572         0,0000
<END>          0,2353         0,2687         0,2021         0,1073         0,0577         0,0506         0,0784

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1758         0,1442         0,1253         0,1259         0,1403         0,1465         0,1421
je             0,1704         0,1422         0,1253         0,1271         0,1422         0,1486         0,1442
<UNK>          0,1653         0,1400         0,1256         0,1285         0,1445         0,1507         0,1454
<UNK>          0,1618         0,1382         0,1256         0,1297         0,1466         0,1525         0,1456
<UNK>          0,1606         0,1374         0,1258         0,1302         0,1476         0,1532         0,1453
pas            0,1606         0,1375         0,1262         0,1304         0,1475         0,1529         0,1449
<END>          0,1616         0,1393         0,1274         0,1303         0,1459         0,1510         0,1446

Perte pour ce batch: 3.1880534
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1315         0,1312         0,1484         0,1734         0,2012         0,2143         0,0000
ce             0,1385         0,1371         0,1522         0,1724         0,1947         0,2051         0,0000
film           0,1422         0,1419         0,1562         0,1722         0,1897         0,1978         0,0000
est            0,1419         0,1451         0,1600         0,1730         0,1867         0,1933         0,0000
excellent      0,1382         0,1448         0,1614         0,1744         0,1875         0,1938         0,0000
<END>          0,1364         0,1437         0,1608         0,1751         0,1890         0,1950         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4798         0,5202         0,0000         0,0000         0,0000         0,0000         0,0000
film           0,3410         0,3728         0,2862         0,0000         0,0000         0,0000         0,0000
est            0,2906         0,3243         0,2484         0,1367         0,0000         0,0000         0,0000
excellent      0,2642         0,3030         0,2341         0,1290         0,0697         0,0000         0,0000
<END>          0,2456         0,2852         0,2218         0,1224         0,0661         0,0588         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
-
-
----------------------------------------------------------------------------------------------------------------------
<START>        0,1968         0,1658         0,1460         0,1489         0,1672         0,1753         0,0000
le             0,1908         0,1635         0,1463         0,1506         0,1702         0,1787         0,0000
film           0,1851         0,1610         0,1465         0,1524         0,1733         0,1818         0,0000
est            0,1810         0,1587         0,1463         0,1537         0,1761         0,1841         0,0000
excellent      0,1795         0,1574         0,1461         0,1542         0,1777         0,1850         0,0000
<END>          0,1795         0,1578         0,1468         0,1545         0,1772         0,1842         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1093         0,1084         0,1222         0,1453         0,1676         0,1774         0,1697
je             0,1161         0,1143         0,1260         0,1452         0,1634         0,1709         0,1641
suis           0,1192         0,1185         0,1296         0,1454         0,1603         0,1661         0,1609
triste         0,1187         0,1213         0,1329         0,1461         0,1582         0,1630         0,1598
<UNK>          0,1157         0,1216         0,1346         0,1470         0,1579         0,1625         0,1607
<UNK>          0,1141         0,1206         0,1340         0,1476         0,1592         0,1637         0,1608
<UNK>          0,1145         0,1189         0,1316         0,1476         0,1617         0,1660         0,1596

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4798         0,5202         0,0000         0,0000         0,0000         0,0000         0,0000
suis           0,3419         0,3736         0,2845         0,0000         0,0000         0,0000         0,0000
triste         0,2920         0,3255         0,2476         0,1349         0,0000         0,0000         0,0000
<END>          0,2666         0,3039         0,2327         0,1267         0,0700         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1702         0,1415         0,1247         0,1273         0,1427         0,1499         0,1437
je             0,1647         0,1393         0,1247         0,1283         0,1448         0,1523         0,1458
suis           0,1596         0,1370         0,1247         0,1298         0,1473         0,1547         0,1470
triste         0,1559         0,1348         0,1245         0,1310         0,1497         0,1570         0,1472
<END>          0,1543         0,1337         0,1245         0,1316         0,1509         0,1579         0,1470
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 3.0083244
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1328         0,1325         0,1484         0,1735         0,1999         0,2129         0,0000
ce             0,1400         0,1386         0,1524         0,1724         0,1932         0,2035         0,0000
temps          0,1436         0,1432         0,1561         0,1721         0,1886         0,1965         0,0000
est            0,1431         0,1465         0,1600         0,1730         0,1857         0,1917         0,0000
agréable       0,1393         0,1461         0,1613         0,1743         0,1867         0,1922         0,0000
<END>          0,1373         0,1448         0,1607         0,1751         0,1884         0,1937         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             temps          est            agréable       <END>          <PAD>
-
-
----------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4775         0,5225         0,0000         0,0000         0,0000         0,0000         0,0000
temps          0,3363         0,3713         0,2924         0,0000         0,0000         0,0000         0,0000
est            0,2851         0,3219         0,2532         0,1398         0,0000         0,0000         0,0000
agréable       0,2586         0,2999         0,2381         0,1312         0,0722         0,0000         0,0000
<END>          0,2395         0,2819         0,2254         0,1245         0,0685         0,0601         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1937         0,1646         0,1466         0,1498         0,1677         0,1776         0,0000
le             0,1875         0,1621         0,1467         0,1515         0,1709         0,1812         0,0000
temps          0,1816         0,1593         0,1466         0,1533         0,1745         0,1848         0,0000
est            0,1772         0,1568         0,1464         0,1546         0,1775         0,1874         0,0000
agréable       0,1752         0,1553         0,1461         0,1553         0,1793         0,1888         0,0000
<END>          0,1753         0,1556         0,1467         0,1554         0,1790         0,1880         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1676         0,1688         0,1871         0,2221         0,2543         0,0000         0,0000
quelle         0,1747         0,1748         0,1892         0,2178         0,2434         0,0000         0,0000
belle          0,1774         0,1799         0,1928         0,2156         0,2343         0,0000         0,0000
journée        0,1752         0,1821         0,1963         0,2160         0,2303         0,0000         0,0000
<END>          0,1713         0,1820         0,1987         0,2177         0,2303         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          <END>          <PAD>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
quelle         0,4706         0,5294         0,0000         0,0000         0,0000         0,0000         0,0000
belle          0,3325         0,3779         0,2896         0,0000         0,0000         0,0000         0,0000
<END>          0,2828         0,3291         0,2525         0,1356         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2335         0,1998         0,1785         0,1827         0,2055         0,0000         0,0000
quelle         0,2282         0,1975         0,1791         0,1855         0,2097         0,0000         0,0000
belle          0,2216         0,1946         0,1799         0,1888         0,2150         0,0000         0,0000
<END>          0,2169         0,1923         0,1806         0,1912         0,2190         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.9572926
Epoch 4 completed with average loss: 0.017300313
Epoch 4 Loss: 0.017300313
Epoch 5
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1334         0,1342         0,1481         0,1740         0,1987         0,2116         0,0000
chat           0,1401         0,1400         0,1516         0,1730         0,1926         0,2027         0,0000
<UNK>          0,1441         0,1455         0,1560         0,1730         0,1868         0,1947         0,0000
la             0,1427         0,1479         0,1595         0,1746         0,1842         0,1911         0,0000
souris         0,1399         0,1485         0,1614         0,1762         0,1835         0,1904         0,0000
<END>          0,1373         0,1467         0,1606         0,1772         0,1857         0,1925         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           <UNK>          <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4734         0,5266         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3321         0,3732         0,2947         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2800         0,3221         0,2546         0,1433         0,0000         0,0000         0,0000
<END>          0,2536         0,2992         0,2386         0,1341         0,0746         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1901         0,1633         0,1456         0,1507         0,1702         0,1801         0,0000
le             0,1841         0,1606         0,1456         0,1526         0,1734         0,1837         0,0000
chat           0,1774         0,1572         0,1456         0,1547         0,1773         0,1877         0,0000
<UNK>          0,1726         0,1542         0,1451         0,1561         0,1809         0,1911         0,0000
<END>          0,1705         0,1526         0,1446         0,1566         0,1829         0,1929         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1335         0,1333         0,1472         0,1730         0,2012         0,2119         0,0000
chiens         0,1409         0,1399         0,1511         0,1718         0,1943         0,2021         0,0000
aiment         0,1444         0,1447         0,1549         0,1718         0,1892         0,1949         0,0000
le             0,1428         0,1466         0,1581         0,1732         0,1875         0,1918         0,0000
jardin         0,1395         0,1467         0,1602         0,1749         0,1875         0,1912         0,0000
<END>          0,1375         0,1453         0,1596         0,1755         0,1893         0,1928         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        les            chiens         aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
les            0,4752         0,5248         0,0000         0,0000         0,0000         0,0000         0,0000
chiens         0,3326         0,3713         0,2961         0,0000         0,0000         0,0000         0,0000
aiment         0,2800         0,3202         0,2553         0,1445         0,0000         0,0000         0,0000
<END>          0,2532         0,2975         0,2395         0,1352         0,0746         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
-
-
----------------------------------------------------------------------------------------------------------------------
<START>        0,1897         0,1638         0,1450         0,1515         0,1701         0,1799         0,0000
les            0,1837         0,1613         0,1450         0,1532         0,1732         0,1835         0,0000
chiens         0,1773         0,1579         0,1448         0,1551         0,1772         0,1877         0,0000
aiment         0,1726         0,1548         0,1443         0,1564         0,1807         0,1911         0,0000
<END>          0,1706         0,1531         0,1440         0,1569         0,1826         0,1928         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.6162548
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1345         0,1353         0,1477         0,1732         0,1988         0,2105         0,0000
chat           0,1413         0,1413         0,1512         0,1721         0,1927         0,2014         0,0000
aiment         0,1454         0,1469         0,1555         0,1719         0,1869         0,1934         0,0000
les            0,1432         0,1488         0,1588         0,1736         0,1851         0,1906         0,0000
chiens         0,1402         0,1492         0,1608         0,1751         0,1848         0,1899         0,0000
<END>          0,1380         0,1476         0,1600         0,1757         0,1869         0,1918         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4703         0,5297         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3268         0,3722         0,3010         0,0000         0,0000         0,0000         0,0000
aiment         0,2740         0,3196         0,2589         0,1475         0,0000         0,0000         0,0000
<END>          0,2467         0,2957         0,2421         0,1371         0,0785         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1860         0,1611         0,1446         0,1521         0,1737         0,1825         0,0000
le             0,1799         0,1583         0,1445         0,1538         0,1770         0,1865         0,0000
chat           0,1731         0,1547         0,1442         0,1558         0,1812         0,1910         0,0000
aiment         0,1682         0,1515         0,1435         0,1570         0,1850         0,1948         0,0000
<END>          0,1656         0,1494         0,1429         0,1575         0,1875         0,1971         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1345         0,1353         0,1477         0,1727         0,1994         0,2105         0,0000
chat           0,1413         0,1412         0,1514         0,1716         0,1932         0,2014         0,0000
sur            0,1457         0,1470         0,1559         0,1713         0,1871         0,1930         0,0000
le             0,1435         0,1488         0,1589         0,1730         0,1854         0,1905         0,0000
tapis          0,1401         0,1490         0,1607         0,1748         0,1854         0,1901         0,0000
<END>          0,1380         0,1476         0,1599         0,1755         0,1872         0,1918         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           sur            <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4701         0,5299         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3267         0,3721         0,3012         0,0000         0,0000         0,0000         0,0000
sur            0,2730         0,3190         0,2587         0,1493         0,0000         0,0000         0,0000
<END>          0,2459         0,2951         0,2417         0,1389         0,0784         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1862         0,1612         0,1448         0,1523         0,1728         0,1826         0,0000
le             0,1801         0,1584         0,1447         0,1541         0,1762         0,1865         0,0000
chat           0,1732         0,1548         0,1444         0,1560         0,1805         0,1910         0,0000
sur            0,1681         0,1514         0,1437         0,1572         0,1846         0,1950         0,0000
<END>          0,1656         0,1494         0,1432         0,1578         0,1868         0,1971         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.5530248
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1354         0,1348         0,1501         0,1729         0,1975         0,2093         0,0000
ce             0,1427         0,1412         0,1542         0,1718         0,1907         0,1994         0,0000
livre          0,1457         0,1456         0,1578         0,1718         0,1862         0,1929         0,0000
est            0,1453         0,1489         0,1617         0,1727         0,1830         0,1885         0,0000
intéressant    0,1408         0,1481         0,1629         0,1744         0,1840         0,1897         0,0000
<END>          0,1387         0,1466         0,1621         0,1752         0,1859         0,1915         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4670         0,5330         0,0000         0,0000         0,0000         0,0000         0,0000
livre          0,3219         0,3717         0,3064         0,0000         0,0000         0,0000         0,0000
est            0,2668         0,3167         0,2609         0,1557         0,0000         0,0000         0,0000
intéressant    0,2384         0,2919         0,2424         0,1442         0,0831         0,0000         0,0000
<END>          0,2185         0,2719         0,2275         0,1357         0,0782         0,0682         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1826         0,1588         0,1446         0,1526         0,1748         0,1865         0,0000
le             0,1759         0,1558         0,1444         0,1544         0,1785         0,1909         0,0000
livre          0,1691         0,1520         0,1438         0,1563         0,1830         0,1958         0,0000
est            0,1636         0,1484         0,1427         0,1576         0,1874         0,2003         0,0000
intéressant    0,1606         0,1458         0,1417         0,1583         0,1904         0,2032         0,0000
<END>          0,1605         0,1459         0,1421         0,1585         0,1902         0,2028         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1130         0,1118         0,1246         0,1451         0,1654         0,1733         0,1667
je             0,1202         0,1182         0,1291         0,1454         0,1609         0,1661         0,1602
<UNK>          0,1234         0,1226         0,1329         0,1461         0,1578         0,1608         0,1564
<UNK>          0,1219         0,1249         0,1358         0,1473         0,1563         0,1579         0,1559
<UNK>          0,1185         0,1248         0,1369         0,1484         0,1566         0,1576         0,1573
pas            0,1170         0,1240         0,1365         0,1489         0,1577         0,1585         0,1575
ce             0,1171         0,1221         0,1342         0,1487         0,1601         0,1613         0,1565

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            <END>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4671         0,5329         0,0000         0,0000         0,0000         0,0000         0,0000
<UNK>          0,3229         0,3725         0,3046         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2680         0,3179         0,2598         0,1542         0,0000         0,0000         0,0000
<UNK>          0,2401         0,2928         0,2410         0,1427         0,0835         0,0000         0,0000
pas            0,2203         0,2727         0,2258         0,1338         0,0783         0,0692         0,0000
<END>          0,2023         0,2491         0,2059         0,1215         0,0702         0,0613         0,0897

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1564         0,1343         0,1224         0,1296         0,1496         0,1581         0,1497
je             0,1504         0,1315         0,1220         0,1308         0,1521         0,1611         0,1520
<UNK>          0,1441         0,1280         0,1213         0,1323         0,1557         0,1648         0,1537
<UNK>          0,1389         0,1244         0,1201         0,1334         0,1595         0,1689         0,1548
<UNK>          0,1365         0,1224         0,1193         0,1338         0,1616         0,1712         0,1552
pas            0,1362         0,1222         0,1194         0,1339         0,1619         0,1713         0,1551
<END>          0,1382         0,1246         0,1210         0,1338         0,1595         0,1685         0,1545

Perte pour ce batch: 2.9713237
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1360         0,1354         0,1509         0,1727         0,1969         0,2081         0,0000
ce             0,1434         0,1418         0,1552         0,1715         0,1898         0,1982         0,0000
film           0,1469         0,1466         0,1592         0,1714         0,1849         0,1910         0,0000
est            0,1456         0,1492         0,1628         0,1724         0,1826         0,1875         0,0000
excellent      0,1407         0,1481         0,1637         0,1740         0,1843         0,1892         0,0000
<END>          0,1387         0,1467         0,1631         0,1748         0,1861         0,1907         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4635         0,5365         0,0000         0,0000         0,0000         0,0000         0,0000
film           0,3158         0,3705         0,3137         0,0000         0,0000         0,0000         0,0000
est            0,2593         0,3130         0,2653         0,1624         0,0000         0,0000         0,0000
excellent      0,2296         0,2870         0,2460         0,1500         0,0874         0,0000         0,0000
<END>          0,2099         0,2663         0,2298         0,1403         0,0817         0,0721         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1781         0,1560         0,1436         0,1534         0,1792         0,1896         0,0000
le             0,1713         0,1529         0,1434         0,1552         0,1830         0,1943         0,0000
film           0,1639         0,1487         0,1426         0,1572         0,1880         0,1996         0,0000
est            0,1581         0,1446         0,1411         0,1584         0,1930         0,2048         0,0000
excellent      0,1548         0,1416         0,1397         0,1590         0,1966         0,2083         0,0000
<END>          0,1546         0,1417         0,1401         0,1592         0,1965         0,2079         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1136         0,1122         0,1250         0,1456         0,1647         0,1730         0,1661
je             0,1208         0,1186         0,1293         0,1454         0,1600         0,1658         0,1601
suis           0,1237         0,1229         0,1329         0,1456         0,1570         0,1611         0,1568
triste         0,1223         0,1251         0,1359         0,1464         0,1555         0,1587         0,1561
<UNK>          0,1183         0,1247         0,1372         0,1474         0,1558         0,1590         0,1576
<UNK>          0,1164         0,1235         0,1365         0,1479         0,1573         0,1605         0,1579
<UNK>          0,1172         0,1221         0,1342         0,1480         0,1595         0,1625         0,1566

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4632         0,5368         0,0000         0,0000         0,0000         0,0000         0,0000
suis           0,3162         0,3714         0,3124         0,0000         0,0000         0,0000         0,0000
triste         0,2599         0,3140         0,2646         0,1616         0,0000         0,0000         0,0000
<END>          0,2310         0,2876         0,2446         0,1485         0,0884         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1525         0,1318         0,1216         0,1306         0,1516         0,1613         0,1506
je             0,1464         0,1289         0,1211         0,1317         0,1543         0,1646         0,1529
suis           0,1399         0,1252         0,1203         0,1331         0,1582         0,1688         0,1546
triste         0,1344         0,1212         0,1188         0,1342         0,1624         0,1734         0,1556
<END>          0,1316         0,1188         0,1178         0,1347         0,1650         0,1761         0,1560
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.903382
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1365         0,1358         0,1504         0,1729         0,1962         0,2082         0,0000
ce             0,1439         0,1423         0,1547         0,1717         0,1891         0,1981         0,0000
temps          0,1470         0,1468         0,1585         0,1716         0,1848         0,1914         0,0000
est            0,1457         0,1494         0,1620         0,1725         0,1828         0,1876         0,0000
agréable       0,1408         0,1481         0,1628         0,1742         0,1848         0,1894         0,0000
<END>          0,1384         0,1465         0,1621         0,1750         0,1868         0,1911         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4602         0,5398         0,0000         0,0000         0,0000         0,0000         0,0000
temps          0,3096         0,3685         0,3219         0,0000         0,0000         0,0000         0,0000
est            0,2516         0,3089         0,2705         0,1689         0,0000         0,0000         0,0000
agréable       0,2211         0,2813         0,2494         0,1549         0,0934         0,0000         0,0000
<END>          0,2007         0,2597         0,2322         0,1444         0,0871         0,0759         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1762         0,1549         0,1437         0,1541         0,1795         0,1917         0,0000
le             0,1691         0,1515         0,1433         0,1559         0,1836         0,1965         0,0000
temps          0,1614         0,1470         0,1423         0,1578         0,1890         0,2024         0,0000
est            0,1551         0,1425         0,1406         0,1592         0,1945         0,2082         0,0000
agréable       0,1513         0,1392         0,1391         0,1598         0,1983         0,2123         0,0000
<END>          0,1511         0,1391         0,1393         0,1599         0,1984         0,2122         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1712         0,1717         0,1884         0,2200         0,2487         0,0000         0,0000
quelle         0,1785         0,1782         0,1908         0,2155         0,2370         0,0000         0,0000
belle          0,1806         0,1831         0,1945         0,2135         0,2283         0,0000         0,0000
journée        0,1773         0,1846         0,1979         0,2145         0,2258         0,0000         0,0000
<END>          0,1724         0,1837         0,1999         0,2168         0,2272         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          <END>          <PAD>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
quelle         0,4563         0,5437         0,0000         0,0000         0,0000         0,0000         0,0000
belle          0,3078         0,3730         0,3192         0,0000         0,0000         0,0000         0,0000
<END>          0,2513         0,3147         0,2703         0,1637         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2161         0,1910         0,1780         0,1917         0,2231         0,0000         0,0000
quelle         0,2097         0,1880         0,1784         0,1951         0,2288         0,0000         0,0000
belle          0,2014         0,1835         0,1784         0,1993         0,2374         0,0000         0,0000
<END>          0,1947         0,1791         0,1779         0,2027         0,2455         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.857554
Epoch 5 completed with average loss: 0.016490556
Epoch 5 Loss: 0.016490556
Epoch 6
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1363         0,1368         0,1494         0,1734         0,1961         0,2079         0,0000
chat           0,1432         0,1430         0,1532         0,1724         0,1896         0,1985         0,0000
<UNK>          0,1468         0,1482         0,1576         0,1726         0,1841         0,1908         0,0000
la             0,1442         0,1498         0,1607         0,1745         0,1824         0,1884         0,0000
souris         0,1404         0,1495         0,1621         0,1763         0,1827         0,1889         0,0000
<END>          0,1375         0,1474         0,1611         0,1774         0,1851         0,1914         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           <UNK>          <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4560         0,5440         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,3042         0,3688         0,3270         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2444         0,3063         0,2733         0,1759         0,0000         0,0000         0,0000
<END>          0,2139         0,2771         0,2504         0,1604         0,0982         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1754         0,1543         0,1428         0,1547         0,1804         0,1923         0,0000
le             0,1684         0,1508         0,1425         0,1567         0,1844         0,1971         0,0000
chat           0,1599         0,1457         0,1413         0,1590         0,1904         0,2037         0,0000
<UNK>          0,1528         0,1404         0,1392         0,1605         0,1966         0,2105         0,0000
<END>          0,1488         0,1369         0,1374         0,1610         0,2007         0,2152         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1366         0,1359         0,1484         0,1723         0,1986         0,2083         0,0000
chiens         0,1443         0,1429         0,1527         0,1711         0,1913         0,1978         0,0000
aiment         0,1472         0,1474         0,1565         0,1712         0,1866         0,1911         0,0000
le             0,1444         0,1484         0,1593         0,1729         0,1858         0,1893         0,0000
jardin         0,1400         0,1476         0,1608         0,1749         0,1869         0,1899         0,0000
<END>          0,1378         0,1459         0,1601         0,1756         0,1889         0,1917         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        les            chiens         aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
les            0,4578         0,5422         0,0000         0,0000         0,0000         0,0000         0,0000
chiens         0,3044         0,3667         0,3289         0,0000         0,0000         0,0000         0,0000
aiment         0,2441         0,3044         0,2745         0,1769         0,0000         0,0000         0,0000
<END>          0,2133         0,2756         0,2519         0,1612         0,0980         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1751         0,1549         0,1422         0,1553         0,1803         0,1922         0,0000
les            0,1682         0,1516         0,1418         0,1572         0,1842         0,1969         0,0000
chiens         0,1598         0,1464         0,1405         0,1593         0,1902         0,2037         0,0000
aiment         0,1528         0,1411         0,1385         0,1606         0,1964         0,2106         0,0000
<END>          0,1489         0,1375         0,1368         0,1611         0,2005         0,2152         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.5465083
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1370         0,1373         0,1484         0,1727         0,1969         0,2077         0,0000
chat           0,1439         0,1436         0,1522         0,1716         0,1905         0,1982         0,0000
aiment         0,1475         0,1490         0,1565         0,1715         0,1849         0,1906         0,0000
les            0,1441         0,1499         0,1594         0,1735         0,1841         0,1890         0,0000
chiens         0,1401         0,1494         0,1609         0,1752         0,1848         0,1896         0,0000
<END>          0,1376         0,1475         0,1599         0,1760         0,1872         0,1919         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4524         0,5476         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2977         0,3666         0,3357         0,0000         0,0000         0,0000         0,0000
aiment         0,2369         0,3019         0,2786         0,1826         0,0000         0,0000         0,0000
<END>          0,2049         0,2710         0,2541         0,1650         0,1051         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1742         0,1532         0,1418         0,1552         0,1825         0,1931         0,0000
le             0,1670         0,1496         0,1414         0,1571         0,1867         0,1982         0,0000
chat           0,1581         0,1442         0,1400         0,1593         0,1931         0,2055         0,0000
aiment         0,1507         0,1386         0,1376         0,1605         0,1997         0,2129         0,0000
<END>          0,1460         0,1344         0,1355         0,1610         0,2046         0,2184         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1370         0,1374         0,1486         0,1720         0,1973         0,2077         0,0000
chat           0,1439         0,1435         0,1526         0,1709         0,1909         0,1982         0,0000
sur            0,1479         0,1491         0,1570         0,1708         0,1851         0,1902         0,0000
le             0,1444         0,1499         0,1596         0,1727         0,1845         0,1890         0,0000
tapis          0,1399         0,1492         0,1608         0,1748         0,1854         0,1899         0,0000
<END>          0,1376         0,1475         0,1599         0,1756         0,1875         0,1919         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           sur            <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4523         0,5477         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2978         0,3666         0,3356         0,0000         0,0000         0,0000         0,0000
sur            0,2359         0,3012         0,2781         0,1848         0,0000         0,0000         0,0000
<END>          0,2043         0,2704         0,2532         0,1670         0,1051         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1744         0,1533         0,1420         0,1555         0,1817         0,1931         0,0000
le             0,1672         0,1497         0,1416         0,1574         0,1860         0,1982         0,0000
chat           0,1582         0,1442         0,1402         0,1595         0,1925         0,2054         0,0000
sur            0,1505         0,1384         0,1378         0,1608         0,1994         0,2132         0,0000
<END>          0,1460         0,1344         0,1358         0,1614         0,2040         0,2184         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.4368057
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1375         0,1364         0,1509         0,1724         0,1958         0,2070         0,0000
ce             0,1449         0,1430         0,1552         0,1712         0,1888         0,1968         0,0000
livre          0,1473         0,1470         0,1588         0,1714         0,1847         0,1908         0,0000
est            0,1457         0,1493         0,1621         0,1725         0,1825         0,1878         0,0000
intéressant    0,1401         0,1476         0,1628         0,1745         0,1846         0,1904         0,0000
<END>          0,1378         0,1459         0,1618         0,1753         0,1867         0,1924         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4489         0,5511         0,0000         0,0000         0,0000         0,0000         0,0000
livre          0,2924         0,3658         0,3417         0,0000         0,0000         0,0000         0,0000
est            0,2287         0,2975         0,2793         0,1945         0,0000         0,0000         0,0000
intéressant    0,1951         0,2647         0,2521         0,1746         0,1135         0,0000         0,0000
<END>          0,1735         0,2398         0,2305         0,1602         0,1040         0,0919         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1734         0,1521         0,1421         0,1549         0,1823         0,1952         0,0000
le             0,1654         0,1482         0,1415         0,1569         0,1870         0,2010         0,0000
livre          0,1562         0,1426         0,1397         0,1590         0,1938         0,2087         0,0000
est            0,1480         0,1363         0,1368         0,1604         0,2013         0,2172         0,0000
intéressant    0,1427         0,1315         0,1342         0,1610         0,2069         0,2237         0,0000
<END>          0,1421         0,1311         0,1342         0,1611         0,2074         0,2241         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1151         0,1132         0,1254         0,1450         0,1643         0,1715         0,1654
je             0,1224         0,1199         0,1302         0,1453         0,1596         0,1639         0,1587
<UNK>          0,1251         0,1240         0,1338         0,1461         0,1569         0,1591         0,1551
<UNK>          0,1225         0,1253         0,1362         0,1475         0,1562         0,1572         0,1552
<UNK>          0,1180         0,1244         0,1367         0,1487         0,1572         0,1578         0,1572
pas            0,1162         0,1234         0,1362         0,1491         0,1585         0,1590         0,1576
ce             0,1169         0,1219         0,1341         0,1489         0,1606         0,1613         0,1563

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            <END>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4472         0,5528         0,0000         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2916         0,3673         0,3410         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2280         0,2989         0,2792         0,1940         0,0000         0,0000         0,0000
<UNK>          0,1951         0,2657         0,2513         0,1737         0,1141         0,0000         0,0000
pas            0,1734         0,2405         0,2291         0,1587         0,1041         0,0941         0,0000
<END>          0,1567         0,2149         0,2038         0,1410         0,0918         0,0821         0,1097

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1478         0,1281         0,1197         0,1311         0,1548         0,1649         0,1535
je             0,1406         0,1246         0,1190         0,1325         0,1581         0,1689         0,1563
<UNK>          0,1323         0,1193         0,1172         0,1341         0,1634         0,1750         0,1587
<UNK>          0,1246         0,1135         0,1143         0,1350         0,1695         0,1822         0,1609
<UNK>          0,1204         0,1096         0,1121         0,1352         0,1735         0,1871         0,1621
pas            0,1195         0,1089         0,1117         0,1352         0,1743         0,1881         0,1624
<END>          0,1229         0,1122         0,1140         0,1351         0,1707         0,1836         0,1614

Perte pour ce batch: 2.8715298
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1379         0,1367         0,1514         0,1722         0,1955         0,2064         0,0000
ce             0,1453         0,1433         0,1558         0,1711         0,1883         0,1962         0,0000
film           0,1482         0,1477         0,1597         0,1711         0,1838         0,1895         0,0000
est            0,1456         0,1492         0,1627         0,1723         0,1827         0,1875         0,0000
excellent      0,1396         0,1470         0,1630         0,1742         0,1855         0,1907         0,0000
<END>          0,1374         0,1454         0,1622         0,1751         0,1875         0,1924         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4453         0,5547         0,0000         0,0000         0,0000         0,0000         0,0000
film           0,2855         0,3633         0,3512         0,0000         0,0000         0,0000         0,0000
est            0,2198         0,2915         0,2841         0,2046         0,0000         0,0000         0,0000
excellent      0,1847         0,2567         0,2549         0,1826         0,1212         0,0000         0,0000
<END>          0,1633         0,2309         0,2312         0,1659         0,1099         0,0987         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1711         0,1503         0,1413         0,1550         0,1855         0,1967         0,0000
le             0,1628         0,1461         0,1407         0,1571         0,1905         0,2028         0,0000
film           0,1528         0,1399         0,1386         0,1593         0,1981         0,2113         0,0000
est            0,1440         0,1331         0,1352         0,1605         0,2065         0,2207         0,0000
excellent      0,1382         0,1276         0,1320         0,1609         0,2131         0,2281         0,0000
<END>          0,1375         0,1272         0,1319         0,1611         0,2137         0,2286         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1154         0,1133         0,1256         0,1455         0,1638         0,1717         0,1648
je             0,1226         0,1199         0,1301         0,1454         0,1590         0,1643         0,1587
suis           0,1249         0,1238         0,1336         0,1456         0,1563         0,1601         0,1556
triste         0,1225         0,1250         0,1360         0,1465         0,1556         0,1587         0,1556
<UNK>          0,1174         0,1237         0,1367         0,1475         0,1568         0,1600         0,1578
<UNK>          0,1152         0,1223         0,1357         0,1481         0,1585         0,1618         0,1584
<UNK>          0,1167         0,1214         0,1338         0,1482         0,1602         0,1632         0,1566

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4432         0,5568         0,0000         0,0000         0,0000         0,0000         0,0000
suis           0,2843         0,3649         0,3508         0,0000         0,0000         0,0000         0,0000
triste         0,2186         0,2924         0,2840         0,2051         0,0000         0,0000         0,0000
<END>          0,1846         0,2572         0,2537         0,1819         0,1226         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1461         0,1265         0,1191         0,1319         0,1558         0,1670         0,1536
je             0,1386         0,1229         0,1184         0,1332         0,1593         0,1713         0,1563
suis           0,1299         0,1173         0,1164         0,1347         0,1650         0,1780         0,1587
triste         0,1217         0,1109         0,1131         0,1356         0,1718         0,1861         0,1608
<END>          0,1169         0,1066         0,1106         0,1359         0,1763         0,1917         0,1620
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.7958944
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1383         0,1370         0,1507         0,1725         0,1948         0,2066         0,0000
ce             0,1457         0,1437         0,1553         0,1713         0,1877         0,1964         0,0000
temps          0,1481         0,1475         0,1588         0,1713         0,1840         0,1904         0,0000
est            0,1455         0,1491         0,1617         0,1725         0,1831         0,1880         0,0000
agréable       0,1395         0,1468         0,1619         0,1743         0,1863         0,1912         0,0000
<END>          0,1369         0,1450         0,1611         0,1753         0,1885         0,1932         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4417         0,5583         0,0000         0,0000         0,0000         0,0000         0,0000
temps          0,2786         0,3602         0,3612         0,0000         0,0000         0,0000         0,0000
est            0,2110         0,2854         0,2893         0,2144         0,0000         0,0000         0,0000
agréable       0,1749         0,2482         0,2567         0,1890         0,1312         0,0000         0,0000
<END>          0,1530         0,2215         0,2314         0,1708         0,1185         0,1049         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1717         0,1503         0,1415         0,1552         0,1843         0,1970         0,0000
le             0,1629         0,1460         0,1408         0,1573         0,1896         0,2034         0,0000
temps          0,1523         0,1392         0,1385         0,1595         0,1978         0,2127         0,0000
est            0,1427         0,1317         0,1347         0,1608         0,2068         0,2232         0,0000
agréable       0,1363         0,1259         0,1313         0,1613         0,2138         0,2315         0,0000
<END>          0,1354         0,1251         0,1309         0,1614         0,2147         0,2324         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1731         0,1727         0,1885         0,2188         0,2468         0,0000         0,0000
quelle         0,1804         0,1794         0,1911         0,2143         0,2348         0,0000         0,0000
belle          0,1816         0,1838         0,1948         0,2127         0,2271         0,0000         0,0000
journée        0,1772         0,1842         0,1978         0,2145         0,2264         0,0000         0,0000
<END>          0,1712         0,1823         0,1994         0,2175         0,2295         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          <END>          <PAD>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
quelle         0,4393         0,5607         0,0000         0,0000         0,0000         0,0000         0,0000
belle          0,2774         0,3637         0,3590         0,0000         0,0000         0,0000         0,0000
<END>          0,2113         0,2903         0,2901         0,2083         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2115         0,1870         0,1765         0,1946         0,2304         0,0000         0,0000
quelle         0,2035         0,1831         0,1769         0,1987         0,2378         0,0000         0,0000
belle          0,1922         0,1761         0,1759         0,2044         0,2513         0,0000         0,0000
<END>          0,1823         0,1687         0,1738         0,2092         0,2660         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.779201
Epoch 6 completed with average loss: 0.015931126
Epoch 6 Loss: 0.015931126
Epoch 7
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1383         0,1381         0,1497         0,1729         0,1948         0,2063         0,0000
chat           0,1450         0,1443         0,1536         0,1719         0,1883         0,1968         0,0000
<UNK>          0,1479         0,1491         0,1578         0,1722         0,1833         0,1897         0,0000
la             0,1440         0,1495         0,1603         0,1745         0,1828         0,1889         0,0000
souris         0,1392         0,1481         0,1611         0,1765         0,1842         0,1908         0,0000
<END>          0,1360         0,1458         0,1599         0,1777         0,1869         0,1937         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           <UNK>          <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4381         0,5619         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2729         0,3587         0,3684         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2025         0,2794         0,2919         0,2262         0,0000         0,0000         0,0000
<END>          0,1664         0,2405         0,2565         0,1975         0,1391         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1727         0,1507         0,1410         0,1556         0,1840         0,1962         0,0000
le             0,1638         0,1461         0,1403         0,1579         0,1893         0,2025         0,0000
chat           0,1520         0,1385         0,1377         0,1607         0,1983         0,2128         0,0000
<UNK>          0,1412         0,1299         0,1333         0,1622         0,2085         0,2249         0,0000
<END>          0,1343         0,1236         0,1294         0,1626         0,2160         0,2340         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1385         0,1371         0,1486         0,1716         0,1974         0,2067         0,0000
chiens         0,1462         0,1442         0,1531         0,1705         0,1899         0,1960         0,0000
aiment         0,1484         0,1482         0,1567         0,1708         0,1859         0,1901         0,0000
le             0,1442         0,1479         0,1588         0,1729         0,1864         0,1898         0,0000
jardin         0,1388         0,1461         0,1597         0,1751         0,1885         0,1919         0,0000
<END>          0,1363         0,1442         0,1588         0,1758         0,1908         0,1941         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        les            chiens         aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
les            0,4403         0,5597         0,0000         0,0000         0,0000         0,0000         0,0000
chiens         0,2729         0,3561         0,3710         0,0000         0,0000         0,0000         0,0000
aiment         0,2022         0,2774         0,2940         0,2264         0,0000         0,0000         0,0000
<END>          0,1659         0,2391         0,2587         0,1974         0,1389         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1723         0,1517         0,1404         0,1560         0,1836         0,1960         0,0000
les            0,1637         0,1473         0,1398         0,1583         0,1888         0,2022         0,0000
chiens         0,1520         0,1396         0,1371         0,1608         0,1978         0,2127         0,0000
aiment         0,1413         0,1308         0,1327         0,1621         0,2081         0,2250         0,0000
<END>          0,1345         0,1244         0,1289         0,1624         0,2157         0,2341         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.4472165
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1390         0,1387         0,1486         0,1720         0,1957         0,2061         0,0000
chat           0,1458         0,1449         0,1525         0,1710         0,1893         0,1966         0,0000
aiment         0,1487         0,1498         0,1566         0,1711         0,1842         0,1896         0,0000
les            0,1439         0,1495         0,1588         0,1734         0,1847         0,1897         0,0000
chiens         0,1388         0,1481         0,1597         0,1754         0,1864         0,1917         0,0000
<END>          0,1361         0,1458         0,1585         0,1762         0,1891         0,1944         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4348         0,5652         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2661         0,3551         0,3788         0,0000         0,0000         0,0000         0,0000
aiment         0,1944         0,2733         0,2973         0,2350         0,0000         0,0000         0,0000
<END>          0,1569         0,2321         0,2588         0,2024         0,1498         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1733         0,1508         0,1405         0,1556         0,1847         0,1952         0,0000
le             0,1641         0,1460         0,1397         0,1579         0,1902         0,2020         0,0000
chat           0,1516         0,1379         0,1368         0,1605         0,1999         0,2134         0,0000
aiment         0,1401         0,1286         0,1319         0,1618         0,2110         0,2265         0,0000
<END>          0,1322         0,1214         0,1274         0,1619         0,2198         0,2372         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1390         0,1387         0,1489         0,1713         0,1960         0,2061         0,0000
chat           0,1458         0,1449         0,1530         0,1703         0,1895         0,1965         0,0000
sur            0,1491         0,1499         0,1572         0,1704         0,1844         0,1892         0,0000
le             0,1442         0,1495         0,1591         0,1726         0,1850         0,1897         0,0000
tapis          0,1387         0,1477         0,1597         0,1749         0,1870         0,1920         0,0000
<END>          0,1361         0,1458         0,1585         0,1757         0,1894         0,1944         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           sur            <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4348         0,5652         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2661         0,3552         0,3787         0,0000         0,0000         0,0000         0,0000
sur            0,1934         0,2723         0,2965         0,2377         0,0000         0,0000         0,0000
<END>          0,1563         0,2314         0,2578         0,2048         0,1497         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1736         0,1509         0,1407         0,1557         0,1838         0,1954         0,0000
le             0,1643         0,1462         0,1400         0,1580         0,1894         0,2021         0,0000
chat           0,1518         0,1379         0,1371         0,1606         0,1992         0,2135         0,0000
sur            0,1400         0,1284         0,1321         0,1619         0,2106         0,2270         0,0000
<END>          0,1323         0,1215         0,1279         0,1622         0,2189         0,2373         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.3367493
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1397         0,1378         0,1513         0,1717         0,1943         0,2051         0,0000
ce             0,1470         0,1444         0,1557         0,1706         0,1873         0,1949         0,0000
livre          0,1486         0,1478         0,1591         0,1709         0,1839         0,1897         0,0000
est            0,1457         0,1490         0,1618         0,1723         0,1829         0,1884         0,0000
intéressant    0,1390         0,1461         0,1617         0,1746         0,1861         0,1925         0,0000
<END>          0,1364         0,1443         0,1606         0,1754         0,1884         0,1949         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4314         0,5686         0,0000         0,0000         0,0000         0,0000         0,0000
livre          0,2613         0,3542         0,3845         0,0000         0,0000         0,0000         0,0000
est            0,1863         0,2676         0,2956         0,2505         0,0000         0,0000         0,0000
intéressant    0,1470         0,2239         0,2532         0,2136         0,1622         0,0000         0,0000
<END>          0,1245         0,1941         0,2221         0,1880         0,1425         0,1289         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1746         0,1513         0,1415         0,1546         0,1826         0,1954         0,0000
le             0,1641         0,1460         0,1404         0,1572         0,1890         0,2032         0,0000
livre          0,1512         0,1374         0,1370         0,1598         0,1993         0,2153         0,0000
est            0,1384         0,1272         0,1313         0,1611         0,2116         0,2303         0,0000
intéressant    0,1296         0,1191         0,1261         0,1614         0,2214         0,2423         0,0000
<END>          0,1283         0,1178         0,1253         0,1613         0,2230         0,2443         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1173         0,1144         0,1259         0,1446         0,1633         0,1701         0,1644
je             0,1244         0,1211         0,1308         0,1451         0,1585         0,1623         0,1577
<UNK>          0,1264         0,1247         0,1341         0,1459         0,1563         0,1581         0,1544
<UNK>          0,1226         0,1250         0,1358         0,1474         0,1566         0,1574         0,1554
<UNK>          0,1170         0,1230         0,1357         0,1486         0,1584         0,1591         0,1582
pas            0,1150         0,1218         0,1349         0,1491         0,1599         0,1606         0,1588
ce             0,1162         0,1209         0,1332         0,1489         0,1615         0,1623         0,1571

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            <END>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4295         0,5705         0,0000         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2603         0,3559         0,3838         0,0000         0,0000         0,0000         0,0000
<UNK>          0,1853         0,2688         0,2952         0,2506         0,0000         0,0000         0,0000
<UNK>          0,1469         0,2249         0,2520         0,2130         0,1633         0,0000         0,0000
pas            0,1242         0,1944         0,2198         0,1860         0,1424         0,1332         0,0000
<END>          0,1102         0,1691         0,1897         0,1606         0,1225         0,1135         0,1344

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1490         0,1276         0,1189         0,1310         0,1551         0,1651         0,1533
je             0,1397         0,1230         0,1179         0,1327         0,1595         0,1706         0,1567
<UNK>          0,1280         0,1151         0,1145         0,1345         0,1674         0,1801         0,1604
<UNK>          0,1162         0,1057         0,1090         0,1351         0,1773         0,1925         0,1641
<UNK>          0,1089         0,0990         0,1045         0,1349         0,1843         0,2019         0,1666
pas            0,1072         0,0974         0,1034         0,1346         0,1859         0,2043         0,1672
<END>          0,1126         0,1024         0,1069         0,1346         0,1804         0,1971         0,1659

Perte pour ce batch: 2.802958
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1404         0,1383         0,1519         0,1715         0,1937         0,2042         0,0000
ce             0,1477         0,1450         0,1564         0,1703         0,1865         0,1940         0,0000
film           0,1498         0,1488         0,1600         0,1705         0,1827         0,1882         0,0000
est            0,1459         0,1491         0,1622         0,1720         0,1828         0,1880         0,0000
excellent      0,1387         0,1457         0,1618         0,1742         0,1869         0,1927         0,0000
<END>          0,1362         0,1440         0,1608         0,1752         0,1891         0,1947         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4286         0,5714         0,0000         0,0000         0,0000         0,0000         0,0000
film           0,2548         0,3507         0,3944         0,0000         0,0000         0,0000         0,0000
est            0,1776         0,2599         0,2987         0,2639         0,0000         0,0000         0,0000
excellent      0,1367         0,2137         0,2530         0,2227         0,1739         0,0000         0,0000
<END>          0,1149         0,1834         0,2193         0,1935         0,1507         0,1383         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1738         0,1507         0,1413         0,1543         0,1845         0,1953         0,0000
le             0,1627         0,1450         0,1402         0,1571         0,1914         0,2036         0,0000
film           0,1486         0,1356         0,1364         0,1598         0,2028         0,2169         0,0000
est            0,1349         0,1244         0,1299         0,1609         0,2167         0,2332         0,0000
excellent      0,1252         0,1153         0,1236         0,1608         0,2283         0,2469         0,0000
<END>          0,1238         0,1140         0,1228         0,1608         0,2299         0,2488         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1178         0,1147         0,1262         0,1452         0,1626         0,1701         0,1635
je             0,1249         0,1214         0,1308         0,1451         0,1577         0,1627         0,1574
suis           0,1264         0,1247         0,1340         0,1455         0,1556         0,1591         0,1547
triste         0,1228         0,1248         0,1357         0,1463         0,1558         0,1590         0,1555
<UNK>          0,1166         0,1225         0,1357         0,1475         0,1578         0,1614         0,1586
<UNK>          0,1142         0,1208         0,1346         0,1481         0,1597         0,1634         0,1593
<UNK>          0,1162         0,1206         0,1330         0,1481         0,1609         0,1642         0,1570

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4265         0,5735         0,0000         0,0000         0,0000         0,0000         0,0000
suis           0,2536         0,3521         0,3943         0,0000         0,0000         0,0000         0,0000
triste         0,1760         0,2601         0,2983         0,2656         0,0000         0,0000         0,0000
<END>          0,1366         0,2139         0,2515         0,2225         0,1755         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1487         0,1273         0,1190         0,1315         0,1549         0,1658         0,1529
je             0,1388         0,1223         0,1179         0,1332         0,1597         0,1718         0,1563
suis           0,1265         0,1140         0,1142         0,1349         0,1682         0,1821         0,1600
triste         0,1139         0,1037         0,1081         0,1356         0,1792         0,1960         0,1636
<END>          0,1058         0,0963         0,1031         0,1353         0,1872         0,2065         0,1659
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.7005384
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1414         0,1391         0,1514         0,1717         0,1924         0,2040         0,0000
ce             0,1486         0,1457         0,1560         0,1705         0,1854         0,1938         0,0000
temps          0,1500         0,1489         0,1592         0,1707         0,1825         0,1887         0,0000
est            0,1461         0,1492         0,1615         0,1721         0,1830         0,1881         0,0000
agréable       0,1389         0,1458         0,1610         0,1742         0,1873         0,1928         0,0000
<END>          0,1361         0,1438         0,1600         0,1752         0,1898         0,1952         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4264         0,5736         0,0000         0,0000         0,0000         0,0000         0,0000
temps          0,2495         0,3472         0,4034         0,0000         0,0000         0,0000         0,0000
est            0,1697         0,2526         0,3009         0,2768         0,0000         0,0000         0,0000
agréable       0,1277         0,2035         0,2504         0,2295         0,1889         0,0000         0,0000
<END>          0,1057         0,1727         0,2151         0,1976         0,1624         0,1465         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1757         0,1521         0,1418         0,1543         0,1819         0,1942         0,0000
le             0,1639         0,1460         0,1406         0,1572         0,1893         0,2030         0,0000
temps          0,1489         0,1358         0,1363         0,1600         0,2014         0,2174         0,0000
est            0,1339         0,1236         0,1292         0,1614         0,2163         0,2356         0,0000
agréable       0,1234         0,1139         0,1226         0,1613         0,2281         0,2507         0,0000
<END>          0,1217         0,1122         0,1214         0,1611         0,2302         0,2534         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1764         0,1746         0,1888         0,2169         0,2434         0,0000         0,0000
quelle         0,1834         0,1813         0,1915         0,2124         0,2314         0,0000         0,0000
belle          0,1837         0,1850         0,1951         0,2114         0,2248         0,0000         0,0000
journée        0,1779         0,1843         0,1975         0,2140         0,2262         0,0000         0,0000
<END>          0,1708         0,1813         0,1987         0,2178         0,2314         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          <END>          <PAD>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
quelle         0,4252         0,5748         0,0000         0,0000         0,0000         0,0000         0,0000
belle          0,2487         0,3498         0,4015         0,0000         0,0000         0,0000         0,0000
<END>          0,1703         0,2570         0,3034         0,2694         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2152         0,1884         0,1768         0,1931         0,2265         0,0000         0,0000
quelle         0,2045         0,1831         0,1771         0,1986         0,2367         0,0000         0,0000
belle          0,1885         0,1726         0,1748         0,2067         0,2574         0,0000         0,0000
<END>          0,1733         0,1604         0,1700         0,2139         0,2825         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.698213
Epoch 7 completed with average loss: 0.015404123
Epoch 7 Loss: 0.015404123
Epoch 8
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1418         0,1406         0,1505         0,1718         0,1921         0,2031         0,0000
chat           0,1483         0,1468         0,1546         0,1710         0,1857         0,1935         0,0000
<UNK>          0,1505         0,1510         0,1585         0,1715         0,1813         0,1873         0,0000
la             0,1451         0,1501         0,1602         0,1740         0,1823         0,1883         0,0000
souris         0,1390         0,1477         0,1604         0,1763         0,1848         0,1918         0,0000
<END>          0,1356         0,1450         0,1590         0,1775         0,1878         0,1951         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           <UNK>          <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4249         0,5751         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2457         0,3447         0,4096         0,0000         0,0000         0,0000         0,0000
<UNK>          0,1621         0,2447         0,3009         0,2922         0,0000         0,0000         0,0000
<END>          0,1203         0,1943         0,2469         0,2387         0,1998         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1764         0,1528         0,1417         0,1549         0,1813         0,1928         0,0000
le             0,1646         0,1466         0,1405         0,1581         0,1886         0,2016         0,0000
chat           0,1482         0,1353         0,1359         0,1616         0,2018         0,2172         0,0000
<UNK>          0,1314         0,1215         0,1278         0,1631         0,2185         0,2377         0,0000
<END>          0,1202         0,1111         0,1204         0,1628         0,2312         0,2543         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1421         0,1396         0,1494         0,1706         0,1948         0,2035         0,0000
chiens         0,1497         0,1468         0,1540         0,1696         0,1872         0,1927         0,0000
aiment         0,1510         0,1500         0,1573         0,1701         0,1840         0,1877         0,0000
le             0,1453         0,1485         0,1587         0,1725         0,1859         0,1893         0,0000
jardin         0,1386         0,1454         0,1588         0,1749         0,1893         0,1930         0,0000
<END>          0,1359         0,1433         0,1578         0,1757         0,1918         0,1955         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        les            chiens         aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
les            0,4277         0,5723         0,0000         0,0000         0,0000         0,0000         0,0000
chiens         0,2456         0,3414         0,4130         0,0000         0,0000         0,0000         0,0000
aiment         0,1617         0,2423         0,3036         0,2924         0,0000         0,0000         0,0000
<END>          0,1200         0,1927         0,2495         0,2383         0,1995         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1762         0,1542         0,1411         0,1549         0,1810         0,1926         0,0000
les            0,1646         0,1482         0,1400         0,1580         0,1881         0,2012         0,0000
chiens         0,1482         0,1367         0,1353         0,1611         0,2015         0,2171         0,0000
aiment         0,1316         0,1226         0,1272         0,1624         0,2183         0,2379         0,0000
<END>          0,1205         0,1120         0,1199         0,1620         0,2312         0,2545         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.358049
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1431         0,1417         0,1497         0,1709         0,1926         0,2021         0,0000
chat           0,1496         0,1479         0,1537         0,1699         0,1863         0,1927         0,0000
aiment         0,1517         0,1522         0,1575         0,1702         0,1818         0,1865         0,0000
les            0,1455         0,1507         0,1590         0,1728         0,1836         0,1884         0,0000
chiens         0,1391         0,1481         0,1591         0,1751         0,1865         0,1921         0,0000
<END>          0,1361         0,1455         0,1577         0,1759         0,1895         0,1952         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4232         0,5768         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2400         0,3400         0,4200         0,0000         0,0000         0,0000         0,0000
aiment         0,1549         0,2372         0,3047         0,3033         0,0000         0,0000         0,0000
<END>          0,1118         0,1842         0,2458         0,2426         0,2156         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1756         0,1527         0,1415         0,1553         0,1826         0,1923         0,0000
le             0,1632         0,1461         0,1401         0,1584         0,1905         0,2018         0,0000
chat           0,1460         0,1342         0,1350         0,1615         0,2047         0,2187         0,0000
aiment         0,1284         0,1194         0,1261         0,1626         0,2227         0,2408         0,0000
<END>          0,1160         0,1077         0,1177         0,1616         0,2374         0,2596         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1431         0,1417         0,1501         0,1702         0,1928         0,2022         0,0000
chat           0,1496         0,1479         0,1543         0,1693         0,1864         0,1926         0,0000
sur            0,1521         0,1523         0,1582         0,1695         0,1819         0,1861         0,0000
le             0,1457         0,1506         0,1593         0,1721         0,1839         0,1884         0,0000
tapis          0,1389         0,1477         0,1592         0,1746         0,1871         0,1924         0,0000
<END>          0,1361         0,1455         0,1579         0,1755         0,1898         0,1952         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           sur            <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4232         0,5768         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2400         0,3400         0,4199         0,0000         0,0000         0,0000         0,0000
sur            0,1536         0,2358         0,3035         0,3071         0,0000         0,0000         0,0000
<END>          0,1112         0,1835         0,2446         0,2456         0,2151         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1759         0,1530         0,1417         0,1552         0,1817         0,1925         0,0000
le             0,1635         0,1463         0,1404         0,1583         0,1897         0,2019         0,0000
chat           0,1462         0,1343         0,1353         0,1615         0,2040         0,2188         0,0000
sur            0,1282         0,1192         0,1262         0,1626         0,2222         0,2415         0,0000
<END>          0,1162         0,1079         0,1182         0,1619         0,2361         0,2597         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.2602305
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
-
-
-
-
-
-
-
--------
--------
-
-
-
-
---------------------------------------------------------------------------------------------
<START>        0,1443         0,1413         0,1529         0,1706         0,1906         0,2002         0,0000
ce             0,1513         0,1480         0,1575         0,1695         0,1837         0,1901         0,0000
livre          0,1519         0,1507         0,1606         0,1700         0,1809         0,1858         0,0000
est            0,1476         0,1506         0,1626         0,1717         0,1812         0,1863         0,0000
intéressant    0,1396         0,1466         0,1618         0,1742         0,1856         0,1921         0,0000
<END>          0,1368         0,1445         0,1605         0,1752         0,1882         0,1948         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4207         0,5793         0,0000         0,0000         0,0000         0,0000         0,0000
livre          0,2364         0,3392         0,4245         0,0000         0,0000         0,0000         0,0000
est            0,1473         0,2305         0,2994         0,3227         0,0000         0,0000         0,0000
intéressant    0,1028         0,1748         0,2357         0,2544         0,2324         0,0000         0,0000
<END>          0,0813         0,1423         0,1949         0,2112         0,1922         0,1781         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1741         0,1522         0,1428         0,1552         0,1817         0,1939         0,0000
le             0,1602         0,1447         0,1408         0,1587         0,1908         0,2047         0,0000
livre          0,1426         0,1323         0,1350         0,1619         0,2057         0,2226         0,0000
est            0,1236         0,1163         0,1248         0,1628         0,2254         0,2471         0,0000
intéressant    0,1104         0,1038         0,1156         0,1616         0,2411         0,2676         0,0000
<END>          0,1082         0,1014         0,1137         0,1610         0,2440         0,2717         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1215         0,1176         0,1276         0,1442         0,1606         0,1664         0,1621
je             0,1285         0,1244         0,1327         0,1446         0,1558         0,1586         0,1553
<UNK>          0,1298         0,1274         0,1356         0,1455         0,1541         0,1551         0,1524
<UNK>          0,1245         0,1265         0,1366         0,1471         0,1554         0,1557         0,1543
<UNK>          0,1177         0,1235         0,1357         0,1484         0,1580         0,1586         0,1579
pas            0,1153         0,1219         0,1347         0,1489         0,1598         0,1604         0,1588
ce             0,1171         0,1216         0,1334         0,1487         0,1610         0,1616         0,1567

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            <END>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4194         0,5806         0,0000         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2354         0,3401         0,4246         0,0000         0,0000         0,0000         0,0000
<UNK>          0,1462         0,2308         0,2994         0,3236         0,0000         0,0000         0,0000
<UNK>          0,1026         0,1750         0,2347         0,2538         0,2339         0,0000         0,0000
pas            0,0808         0,1417         0,1922         0,2081         0,1912         0,1860         0,0000
<END>          0,0709         0,1204         0,1611         0,1743         0,1601         0,1547         0,1585

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1489         0,1287         0,1201         0,1314         0,1544         0,1638         0,1527
je             0,1364         0,1221         0,1182         0,1337         0,1608         0,1716         0,1573
<UNK>          0,1206         0,1108         0,1125         0,1356         0,1723         0,1857         0,1626
<UNK>          0,1035         0,0963         0,1031         0,1356         0,1876         0,2058         0,1681
<UNK>          0,0924         0,0858         0,0951         0,1340         0,1990         0,2220         0,1716
pas            0,0899         0,0833         0,0930         0,1332         0,2017         0,2263         0,1727
<END>          0,0977         0,0903         0,0983         0,1339         0,1934         0,2153         0,1711

Perte pour ce batch: 2.7280078
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1457         0,1426         0,1540         0,1703         0,1890         0,1983         0,0000
ce             0,1527         0,1493         0,1587         0,1691         0,1820         0,1882         0,0000
film           0,1540         0,1525         0,1620         0,1695         0,1788         0,1833         0,0000
est            0,1484         0,1515         0,1634         0,1714         0,1804         0,1849         0,0000
excellent      0,1399         0,1470         0,1622         0,1739         0,1857         0,1913         0,0000
<END>          0,1373         0,1450         0,1611         0,1749         0,1881         0,1936         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4193         0,5807         0,0000         0,0000         0,0000         0,0000         0,0000
film           0,2313         0,3352         0,4336         0,0000         0,0000         0,0000         0,0000
est            0,1395         0,2217         0,2997         0,3392         0,0000         0,0000         0,0000
excellent      0,0936         0,1632         0,2310         0,2625         0,2496         0,0000         0,0000
<END>          0,0733         0,1313         0,1882         0,2143         0,2028         0,1902         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1700         0,1502         0,1428         0,1560         0,1854         0,1955         0,0000
le             0,1554         0,1421         0,1406         0,1596         0,1952         0,2071         0,0000
film           0,1368         0,1287         0,1340         0,1627         0,2115         0,2263         0,0000
est            0,1169         0,1116         0,1226         0,1630         0,2333         0,2526         0,0000
excellent      0,1028         0,0979         0,1118         0,1608         0,2514         0,2753         0,0000
<END>          0,1008         0,0957         0,1100         0,1602         0,2542         0,2792         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1226         0,1186         0,1284         0,1448         0,1593         0,1658         0,1605
je             0,1296         0,1254         0,1332         0,1447         0,1545         0,1583         0,1543
suis           0,1303         0,1281         0,1361         0,1451         0,1528         0,1554         0,1521
triste         0,1254         0,1271         0,1370         0,1461         0,1541         0,1567         0,1538
<UNK>          0,1179         0,1237         0,1364         0,1473         0,1569         0,1602         0,1576
<UNK>          0,1151         0,1217         0,1350         0,1479         0,1590         0,1626         0,1586
<UNK>          0,1178         0,1220         0,1338         0,1480         0,1598         0,1627         0,1559

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4182         0,5818         0,0000         0,0000         0,0000         0,0000         0,0000
suis           0,2302         0,3357         0,4341         0,0000         0,0000         0,0000         0,0000
triste         0,1379         0,2206         0,2989         0,3426         0,0000         0,0000         0,0000
<END>          0,0937         0,1630         0,2298         0,2631         0,2503         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1456         0,1269         0,1202         0,1328         0,1555         0,1658         0,1533
je             0,1326         0,1198         0,1180         0,1351         0,1624         0,1742         0,1578
suis           0,1163         0,1081         0,1120         0,1368         0,1745         0,1893         0,1630
triste         0,0986         0,0927         0,1016         0,1365         0,1914         0,2114         0,1678
<END>          0,0869         0,0817         0,0929         0,1347         0,2040         0,2291         0,1708
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.6240556
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1474         0,1442         0,1540         0,1704         0,1869         0,1971         0,0000
ce             0,1543         0,1508         0,1587         0,1692         0,1800         0,1869         0,0000
temps          0,1548         0,1534         0,1617         0,1695         0,1778         0,1828         0,0000
est            0,1493         0,1525         0,1632         0,1713         0,1797         0,1839         0,0000
agréable       0,1408         0,1479         0,1621         0,1738         0,1852         0,1902         0,0000
<END>          0,1378         0,1456         0,1609         0,1748         0,1880         0,1930         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4191         0,5809         0,0000         0,0000         0,0000         0,0000         0,0000
temps          0,2280         0,3317         0,4403         0,0000         0,0000         0,0000         0,0000
est            0,1334         0,2142         0,2986         0,3539         0,0000         0,0000         0,0000
agréable       0,0866         0,1531         0,2243         0,2672         0,2688         0,0000         0,0000
<END>          0,0663         0,1212         0,1805         0,2155         0,2161         0,2003         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1695         0,1508         0,1436         0,1570         0,1838         0,1954         0,0000
le             0,1539         0,1420         0,1411         0,1608         0,1943         0,2078         0,0000
temps          0,1344         0,1278         0,1340         0,1639         0,2115         0,2284         0,0000
est            0,1134         0,1096         0,1217         0,1640         0,2342         0,2571         0,0000
agréable       0,0987         0,0953         0,1103         0,1617         0,2523         0,2816         0,0000
<END>          0,0964         0,0926         0,1079         0,1607         0,2557         0,2867         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1823         0,1793         0,1905         0,2132         0,2346         0,0000         0,0000
quelle         0,1891         0,1860         0,1934         0,2088         0,2227         0,0000         0,0000
belle          0,1883         0,1892         0,1968         0,2083         0,2175         0,0000         0,0000
journée        0,1811         0,1873         0,1988         0,2118         0,2210         0,0000         0,0000
<END>          0,1728         0,1832         0,1995         0,2164         0,2281         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          <END>          <PAD>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
quelle         0,4191         0,5809         0,0000         0,0000         0,0000         0,0000         0,0000
belle          0,2285         0,3341         0,4374         0,0000         0,0000         0,0000         0,0000
<END>          0,1343         0,2183         0,3016         0,3457         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,2076         0,1867         0,1794         0,1975         0,2289         0,0000         0,0000
quelle         0,1932         0,1790         0,1792         0,2050         0,2435         0,0000         0,0000
belle          0,1721         0,1640         0,1744         0,2159         0,2737         0,0000         0,0000
<END>          0,1503         0,1454         0,1647         0,2254         0,3141         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.5880227
Epoch 8 completed with average loss: 0.01489723
Epoch 8 Loss: 0.01489723
Epoch 9
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1486         0,1465         0,1537         0,1704         0,1859         0,1950         0,0000
chat           0,1548         0,1528         0,1578         0,1696         0,1795         0,1855         0,0000
<UNK>          0,1562         0,1565         0,1614         0,1701         0,1757         0,1800         0,0000
la             0,1491         0,1543         0,1626         0,1730         0,1781         0,1829         0,0000
souris         0,1418         0,1507         0,1621         0,1756         0,1819         0,1880         0,0000
<END>          0,1380         0,1477         0,1605         0,1768         0,1852         0,1917         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           <UNK>          <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4209         0,5791         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2277         0,3292         0,4431         0,0000         0,0000         0,0000         0,0000
<UNK>          0,1280         0,2059         0,2949         0,3712         0,0000         0,0000         0,0000
<END>          0,0813         0,1440         0,2171         0,2745         0,2832         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1681         0,1511         0,1440         0,1586         0,1836         0,1946         0,0000
le             0,1526         0,1421         0,1414         0,1626         0,1943         0,2071         0,0000
chat           0,1315         0,1265         0,1337         0,1664         0,2128         0,2291         0,0000
<UNK>          0,1089         0,1064         0,1198         0,1666         0,2377         0,2607         0,0000
<END>          0,0935         0,0912         0,1073         0,1636         0,2571         0,2873         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1489         0,1455         0,1525         0,1691         0,1885         0,1954         0,0000
chiens         0,1564         0,1528         0,1573         0,1680         0,1809         0,1846         0,0000
aiment         0,1567         0,1555         0,1603         0,1687         0,1783         0,1805         0,0000
le             0,1494         0,1525         0,1610         0,1715         0,1817         0,1839         0,0000
jardin         0,1414         0,1483         0,1604         0,1743         0,1864         0,1892         0,0000
<END>          0,1384         0,1458         0,1592         0,1751         0,1892         0,1922         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        les            chiens         aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
les            0,4247         0,5753         0,0000         0,0000         0,0000         0,0000         0,0000
chiens         0,2277         0,3251         0,4472         0,0000         0,0000         0,0000         0,0000
aiment         0,1275         0,2030         0,2979         0,3715         0,0000         0,0000         0,0000
<END>          0,0810         0,1424         0,2199         0,2737         0,2831         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1680         0,1526         0,1434         0,1580         0,1836         0,1944         0,0000
les            0,1528         0,1438         0,1410         0,1618         0,1939         0,2065         0,0000
chiens         0,1318         0,1280         0,1332         0,1653         0,2127         0,2291         0,0000
aiment         0,1091         0,1074         0,1192         0,1651         0,2379         0,2612         0,0000
<END>          0,0940         0,0921         0,1069         0,1620         0,2575         0,2876         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.280527
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1505         0,1483         0,1531         0,1692         0,1858         0,1931         0,0000
chat           0,1567         0,1546         0,1573         0,1683         0,1795         0,1837         0,0000
aiment         0,1580         0,1585         0,1608         0,1687         0,1757         0,1784         0,0000
les            0,1502         0,1557         0,1617         0,1717         0,1787         0,1820         0,0000
chiens         0,1425         0,1519         0,1613         0,1743         0,1828         0,1872         0,0000
<END>          0,1391         0,1489         0,1596         0,1753         0,1862         0,1908         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4214         0,5786         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2245         0,3250         0,4505         0,0000         0,0000         0,0000         0,0000
aiment         0,1234         0,1997         0,2964         0,3805         0,0000         0,0000         0,0000
<END>          0,0753         0,1355         0,2135         0,2737         0,3020         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1647         0,1499         0,1440         0,1594         0,1861         0,1959         0,0000
le             0,1485         0,1403         0,1409         0,1632         0,1975         0,2096         0,0000
chat           0,1268         0,1240         0,1325         0,1663         0,2171         0,2333         0,0000
aiment         0,1037         0,1030         0,1175         0,1653         0,2436         0,2669         0,0000
<END>          0,0875         0,0867         0,1037         0,1610         0,2652         0,2959         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1505         0,1483         0,1537         0,1685         0,1858         0,1932         0,0000
chat           0,1567         0,1546         0,1580         0,1676         0,1794         0,1837         0,0000
sur            0,1584         0,1586         0,1616         0,1679         0,1755         0,1780         0,0000
le             0,1503         0,1555         0,1622         0,1710         0,1790         0,1820         0,0000
tapis          0,1423         0,1515         0,1614         0,1739         0,1834         0,1875         0,0000
<END>          0,1391         0,1489         0,1599         0,1748         0,1865         0,1908         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           sur            <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4214         0,5786         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2243         0,3248         0,4509         0,0000         0,0000         0,0000         0,0000
sur            0,1215         0,1976         0,2948         0,3860         0,0000         0,0000         0,0000
<END>          0,0747         0,1346         0,2122         0,2779         0,3006         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1650         0,1501         0,1442         0,1593         0,1854         0,1960         0,0000
le             0,1487         0,1404         0,1413         0,1631         0,1969         0,2095         0,0000
chat           0,1270         0,1240         0,1328         0,1664         0,2166         0,2333         0,0000
sur            0,1032         0,1025         0,1175         0,1656         0,2434         0,2678         0,0000
<END>          0,0876         0,0868         0,1042         0,1617         0,2637         0,2960         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.1832035
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1521         0,1483         0,1568         0,1689         0,1833         0,1905         0,0000
ce             0,1589         0,1551         0,1616         0,1676         0,1764         0,1804         0,0000
livre          0,1585         0,1573         0,1646         0,1683         0,1743         0,1770         0,0000
est            0,1526         0,1560         0,1659         0,1704         0,1759         0,1792         0,0000
intéressant    0,1434         0,1509         0,1645         0,1734         0,1814         0,1865         0,0000
<END>          0,1403         0,1485         0,1630         0,1745         0,1842         0,1895         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4205         0,5795         0,0000         0,0000         0,0000         0,0000         0,0000
livre          0,2227         0,3246         0,4528         0,0000         0,0000         0,0000         0,0000
est            0,1172         0,1933         0,2879         0,4015         0,0000         0,0000         0,0000
intéressant    0,0685         0,1270         0,2008         0,2836         0,3200         0,0000         0,0000
<END>          0,0494         0,0953         0,1539         0,2187         0,2449         0,2379         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1602         0,1479         0,1451         0,1609         0,1864         0,1995         0,0000
le             0,1422         0,1370         0,1410         0,1652         0,1995         0,2151         0,0000
livre          0,1205         0,1203         0,1315         0,1681         0,2198         0,2399         0,0000
est            0,0962         0,0979         0,1147         0,1663         0,2481         0,2767         0,0000
intéressant    0,0800         0,0812         0,0999         0,1611         0,2704         0,3074         0,0000
<END>          0,0772         0,0779         0,0967         0,1592         0,2748         0,3143         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1289         0,1240         0,1317         0,1437         0,1554         0,1592         0,1572
je             0,1358         0,1311         0,1369         0,1441         0,1505         0,1513         0,1503
<UNK>          0,1363         0,1337         0,1396         0,1450         0,1492         0,1483         0,1478
<UNK>          0,1294         0,1316         0,1400         0,1468         0,1514         0,1502         0,1505
<UNK>          0,1214         0,1275         0,1385         0,1483         0,1550         0,1543         0,1550
pas            0,1186         0,1255         0,1372         0,1489         0,1571         0,1565         0,1563
ce             0,1209         0,1257         0,1362         0,1485         0,1578         0,1571         0,1538

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            <END>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4206         0,5794         0,0000         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2222         0,3243         0,4535         0,0000         0,0000         0,0000         0,0000
<UNK>          0,1166         0,1927         0,2881         0,4026         0,0000         0,0000         0,0000
<UNK>          0,0682         0,1264         0,1995         0,2822         0,3236         0,0000         0,0000
pas            0,0490         0,0942         0,1511         0,2140         0,2437         0,2480         0,0000
<END>          0,0433         0,0792         0,1240         0,1748         0,1995         0,2021         0,1772

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1367         0,1247         0,1215         0,1353         0,1582         0,1678         0,1559
je             0,1208         0,1152         0,1178         0,1380         0,1673         0,1790         0,1619
<UNK>          0,1016         0,1001         0,1089         0,1394         0,1829         0,1986         0,1684
<UNK>          0,0805         0,0807         0,0941         0,1370         0,2046         0,2284         0,1747
<UNK>          0,0667         0,0667         0,0816         0,1321         0,2213         0,2537         0,1778
pas            0,0640         0,0636         0,0785         0,1302         0,2249         0,2602         0,1787
<END>          0,0731         0,0722         0,0858         0,1326         0,2139         0,2444         0,1779

Perte pour ce batch: 2.6267543
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1540         0,1502         0,1582         0,1685         0,1811         0,1879         0,0000
ce             0,1608         0,1571         0,1631         0,1672         0,1741         0,1778         0,0000
film           0,1613         0,1599         0,1662         0,1677         0,1714         0,1736         0,0000
est            0,1540         0,1576         0,1670         0,1701         0,1743         0,1770         0,0000
excellent      0,1441         0,1519         0,1651         0,1731         0,1809         0,1849         0,0000
<END>          0,1413         0,1497         0,1639         0,1741         0,1835         0,1875         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4214         0,5786         0,0000         0,0000         0,0000         0,0000         0,0000
film           0,2203         0,3213         0,4584         0,0000         0,0000         0,0000         0,0000
est            0,1119         0,1857         0,2854         0,4171         0,0000         0,0000         0,0000
excellent      0,0619         0,1170         0,1930         0,2870         0,3411         0,0000         0,0000
<END>          0,0441         0,0866         0,1456         0,2171         0,2558         0,2509         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1539         0,1447         0,1451         0,1624         0,1915         0,2024         0,0000
le             0,1352         0,1330         0,1406         0,1666         0,2055         0,2191         0,0000
film           0,1128         0,1154         0,1300         0,1691         0,2274         0,2453         0,0000
est            0,0884         0,0921         0,1117         0,1661         0,2580         0,2839         0,0000
excellent      0,0717         0,0745         0,0951         0,1590         0,2827         0,3169         0,0000
<END>          0,0692         0,0715         0,0919         0,1570         0,2870         0,3234         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1304         0,1255         0,1327         0,1443         0,1537         0,1582         0,1552
je             0,1373         0,1326         0,1377         0,1441         0,1487         0,1507         0,1489
suis           0,1373         0,1350         0,1404         0,1446         0,1475         0,1483         0,1470
triste         0,1309         0,1328         0,1407         0,1457         0,1497         0,1508         0,1495
<UNK>          0,1220         0,1283         0,1395         0,1471         0,1534         0,1554         0,1542
<UNK>          0,1189         0,1259         0,1379         0,1478         0,1558         0,1582         0,1555
<UNK>          0,1222         0,1268         0,1370         0,1478         0,1561         0,1576         0,1524

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4217         0,5783         0,0000         0,0000         0,0000         0,0000         0,0000
suis           0,2198         0,3208         0,4594         0,0000         0,0000         0,0000         0,0000
triste         0,1106         0,1837         0,2842         0,4216         0,0000         0,0000         0,0000
<END>          0,0619         0,1163         0,1919         0,2880         0,3419         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1314         0,1218         0,1213         0,1374         0,1600         0,1708         0,1573
je             0,1151         0,1118         0,1173         0,1400         0,1699         0,1829         0,1630
suis           0,0958         0,0964         0,1079         0,1410         0,1862         0,2037         0,1690
triste         0,0746         0,0764         0,0919         0,1377         0,2097         0,2358         0,1738
<END>          0,0607         0,0621         0,0788         0,1322         0,2277         0,2629         0,1755
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.555152
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1562         0,1522         0,1585         0,1685         0,1785         0,1861         0,0000
ce             0,1629         0,1591         0,1634         0,1672         0,1716         0,1758         0,0000
temps          0,1623         0,1613         0,1663         0,1677         0,1700         0,1725         0,0000
est            0,1553         0,1591         0,1673         0,1699         0,1731         0,1752         0,0000
agréable       0,1456         0,1534         0,1657         0,1728         0,1797         0,1828         0,0000
<END>          0,1422         0,1508         0,1643         0,1740         0,1828         0,1860         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4247         0,5753         0,0000         0,0000         0,0000         0,0000         0,0000
temps          0,2203         0,3182         0,4616         0,0000         0,0000         0,0000         0,0000
est            0,1085         0,1797         0,2823         0,4294         0,0000         0,0000         0,0000
agréable       0,0574         0,1091         0,1851         0,2872         0,3611         0,0000         0,0000
<END>          0,0400         0,0793         0,1377         0,2144         0,2676         0,2611         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1526         0,1454         0,1463         0,1639         0,1896         0,2022         0,0000
le             0,1329         0,1329         0,1414         0,1683         0,2046         0,2198         0,0000
temps          0,1097         0,1143         0,1302         0,1708         0,2274         0,2477         0,0000
est            0,0845         0,0899         0,1107         0,1673         0,2585         0,2890         0,0000
agréable       0,0678         0,0720         0,0936         0,1598         0,2826         0,3241         0,0000
<END>          0,0650         0,0685         0,0898         0,1572         0,2874         0,3322         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1907         0,1867         0,1935         0,2079         0,2212         0,0000         0,0000
quelle         0,1972         0,1936         0,1965         0,2034         0,2093         0,0000         0,0000
belle          0,1952         0,1963         0,1999         0,2034         0,2052         0,0000         0,0000
journée        0,1867         0,1934         0,2017         0,2077         0,2105         0,0000         0,0000
<END>          0,1772         0,1883         0,2021         0,2131         0,2193         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          <END>          <PAD>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
quelle         0,4266         0,5734         0,0000         0,0000         0,0000         0,0000         0,0000
belle          0,2213         0,3190         0,4596         0,0000         0,0000         0,0000         0,0000
<END>          0,1090         0,1818         0,2860         0,4232         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1874         0,1805         0,1841         0,2086         0,2393         0,0000         0,0000
quelle         0,1688         0,1695         0,1824         0,2187         0,2605         0,0000         0,0000
belle          0,1430         0,1492         0,1734         0,2316         0,3028         0,0000         0,0000
<END>          0,1157         0,1232         0,1561         0,2414         0,3636         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.459703
Epoch 9 completed with average loss: 0.014359835
Epoch 9 Loss: 0.014359835
Epoch 10
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1577         0,1551         0,1584         0,1684         0,1771         0,1833         0,0000
chat           0,1636         0,1617         0,1628         0,1676         0,1706         0,1737         0,0000
<UNK>          0,1643         0,1651         0,1663         0,1682         0,1672         0,1689         0,0000
la             0,1556         0,1618         0,1670         0,1716         0,1708         0,1732         0,0000
souris         0,1470         0,1570         0,1660         0,1745         0,1757         0,1797         0,0000
<END>          0,1429         0,1536         0,1642         0,1759         0,1795         0,1839         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           <UNK>          <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4309         0,5691         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2248         0,3167         0,4585         0,0000         0,0000         0,0000         0,0000
<UNK>          0,1068         0,1741         0,2773         0,4419         0,0000         0,0000         0,0000
<END>          0,0551         0,1031         0,1779         0,2891         0,3748         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           <UNK>          la             souris         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1531         0,1476         0,1481         0,1657         0,1874         0,1982         0,0000
le             0,1335         0,1349         0,1432         0,1705         0,2023         0,2156         0,0000
chat           0,1086         0,1146         0,1312         0,1739         0,2266         0,2451         0,0000
<UNK>          0,0817         0,0881         0,1098         0,1703         0,2604         0,2897         0,0000
<END>          0,0643         0,0691         0,0912         0,1617         0,2861         0,3275         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1581         0,1541         0,1574         0,1671         0,1795         0,1838         0,0000
chiens         0,1655         0,1618         0,1624         0,1659         0,1717         0,1728         0,0000
aiment         0,1649         0,1640         0,1653         0,1667         0,1697         0,1694         0,0000
le             0,1559         0,1598         0,1656         0,1701         0,1743         0,1743         0,0000
jardin         0,1466         0,1544         0,1644         0,1733         0,1802         0,1811         0,0000
<END>          0,1433         0,1516         0,1630         0,1743         0,1834         0,1844         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        les            chiens         aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
les            0,4356         0,5644         0,0000         0,0000         0,0000         0,0000         0,0000
chiens         0,2251         0,3120         0,4629         0,0000         0,0000         0,0000         0,0000
aiment         0,1060         0,1706         0,2797         0,4437         0,0000         0,0000         0,0000
<END>          0,0548         0,1015         0,1801         0,2887         0,3748         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chiens         aiment         le             jardin         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1532         0,1490         0,1475         0,1642         0,1878         0,1982         0,0000
les            0,1340         0,1365         0,1431         0,1689         0,2023         0,2152         0,0000
chiens         0,1091         0,1158         0,1309         0,1719         0,2270         0,2453         0,0000
aiment         0,0821         0,0888         0,1093         0,1679         0,2612         0,2908         0,0000
<END>          0,0648         0,0697         0,0910         0,1594         0,2870         0,3281         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.2160072
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1598         0,1571         0,1580         0,1672         0,1769         0,1811         0,0000
chat           0,1657         0,1637         0,1625         0,1662         0,1704         0,1715         0,0000
aiment         0,1663         0,1674         0,1660         0,1666         0,1669         0,1668         0,0000
les            0,1569         0,1635         0,1665         0,1702         0,1712         0,1718         0,0000
chiens         0,1480         0,1586         0,1655         0,1733         0,1763         0,1784         0,0000
<END>          0,1442         0,1552         0,1637         0,1743         0,1801         0,1824         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           aiment         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4344         0,5656         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2249         0,3131         0,4620         0,0000         0,0000         0,0000         0,0000
aiment         0,1049         0,1701         0,2784         0,4466         0,0000         0,0000         0,0000
<END>          0,0519         0,0977         0,1749         0,2839         0,3917         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           aiment         les            chiens         <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1521         0,1485         0,1493         0,1655         0,1877         0,1969         0,0000
le             0,1316         0,1351         0,1440         0,1700         0,2035         0,2158         0,0000
chat           0,1059         0,1138         0,1312         0,1727         0,2291         0,2473         0,0000
aiment         0,0787         0,0863         0,1086         0,1677         0,2644         0,2943         0,0000
<END>          0,0606         0,0662         0,0886         0,1575         0,2922         0,3349         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1599         0,1572         0,1586         0,1665         0,1767         0,1812         0,0000
chat           0,1658         0,1638         0,1632         0,1655         0,1701         0,1716         0,0000
sur            0,1668         0,1676         0,1668         0,1658         0,1665         0,1664         0,0000
le             0,1571         0,1633         0,1669         0,1695         0,1713         0,1719         0,0000
tapis          0,1478         0,1582         0,1657         0,1728         0,1768         0,1787         0,0000
<END>          0,1442         0,1553         0,1640         0,1739         0,1802         0,1825         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             chat           sur            <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4344         0,5656         0,0000         0,0000         0,0000         0,0000         0,0000
chat           0,2244         0,3127         0,4628         0,0000         0,0000         0,0000         0,0000
sur            0,1025         0,1674         0,2762         0,4539         0,0000         0,0000         0,0000
<END>          0,0513         0,0967         0,1737         0,2892         0,3890         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        chat           sur            le             tapis          <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1523         0,1486         0,1495         0,1652         0,1874         0,1969         0,0000
le             0,1317         0,1351         0,1443         0,1700         0,2034         0,2155         0,0000
chat           0,1059         0,1136         0,1315         0,1729         0,2291         0,2470         0,0000
sur            0,0780         0,0855         0,1083         0,1682         0,2650         0,2951         0,0000
<END>          0,0606         0,0662         0,0891         0,1588         0,2911         0,3342         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.1400416
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1614         0,1571         0,1619         0,1668         0,1744         0,1785         0,0000
ce             0,1679         0,1642         0,1671         0,1653         0,1673         0,1682         0,0000
livre          0,1666         0,1662         0,1701         0,1662         0,1656         0,1654         0,0000
est            0,1593         0,1638         0,1710         0,1688         0,1683         0,1690         0,0000
intéressant    0,1488         0,1576         0,1691         0,1723         0,1748         0,1774         0,0000
<END>          0,1455         0,1549         0,1675         0,1735         0,1779         0,1808         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4354         0,5646         0,0000         0,0000         0,0000         0,0000         0,0000
livre          0,2252         0,3132         0,4616         0,0000         0,0000         0,0000         0,0000
est            0,1007         0,1656         0,2700         0,4637         0,0000         0,0000         0,0000
intéressant    0,0478         0,0924         0,1648         0,2913         0,4037         0,0000         0,0000
<END>          0,0313         0,0640         0,1177         0,2097         0,2874         0,2898         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             livre          est            intéressant    <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1500         0,1480         0,1512         0,1670         0,1860         0,1978         0,0000
le             0,1271         0,1328         0,1446         0,1726         0,2038         0,2190         0,0000
livre          0,1013         0,1110         0,1306         0,1753         0,2302         0,2516         0,0000
est            0,0731         0,0821         0,1057         0,1694         0,2676         0,3021         0,0000
intéressant    0,0554         0,0620         0,0850         0,1582         0,2955         0,3438         0,0000
<END>          0,0523         0,0580         0,0803         0,1545         0,3013         0,3537         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1378         0,1323         0,1369         0,1431         0,1489         0,1502         0,1508
je             0,1446         0,1399         0,1426         0,1434         0,1438         0,1421         0,1436
<UNK>          0,1444         0,1423         0,1452         0,1445         0,1427         0,1395         0,1414
<UNK>          0,1361         0,1392         0,1451         0,1465         0,1458         0,1424         0,1449
<UNK>          0,1268         0,1339         0,1430         0,1483         0,1502         0,1476         0,1502
pas            0,1234         0,1315         0,1415         0,1489         0,1526         0,1502         0,1518
ce             0,1263         0,1321         0,1407         0,1485         0,1530         0,1503         0,1491

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            <END>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4369         0,5631         0,0000         0,0000         0,0000         0,0000         0,0000
<UNK>          0,2250         0,3115         0,4635         0,0000         0,0000         0,0000         0,0000
<UNK>          0,1002         0,1641         0,2705         0,4652         0,0000         0,0000         0,0000
<UNK>          0,0476         0,0913         0,1640         0,2897         0,4074         0,0000         0,0000
pas            0,0312         0,0631         0,1159         0,2049         0,2846         0,3004         0,0000
<END>          0,0283         0,0533         0,0944         0,1652         0,2306         0,2428         0,1853

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             <UNK>          <UNK>          <UNK>          pas            ce
------------------------------------------------------------------------------------------------------------------------
<START>        0,1281         0,1252         0,1265         0,1403         0,1577         0,1657         0,1565
je             0,1082         0,1120         0,1207         0,1437         0,1702         0,1807         0,1645
<UNK>          0,0854         0,0924         0,1077         0,1445         0,1907         0,2066         0,1727
<UNK>          0,0610         0,0677         0,0864         0,1385         0,2194         0,2474         0,1796
<UNK>          0,0462         0,0510         0,0693         0,1289         0,2408         0,2824         0,1813
pas            0,0435         0,0475         0,0651         0,1254         0,2453         0,2915         0,1817
<END>          0,0531         0,0572         0,0745         0,1303         0,2318         0,2706         0,1824

Perte pour ce batch: 2.5325434
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1632         0,1590         0,1631         0,1665         0,1722         0,1760         0,0000
ce             0,1697         0,1663         0,1683         0,1650         0,1650         0,1657         0,0000
film           0,1694         0,1690         0,1714         0,1656         0,1626         0,1620         0,0000
est            0,1606         0,1655         0,1719         0,1685         0,1667         0,1667         0,0000
excellent      0,1494         0,1587         0,1695         0,1721         0,1743         0,1759         0,0000
<END>          0,1464         0,1563         0,1681         0,1733         0,1772         0,1787         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4384         0,5616         0,0000         0,0000         0,0000         0,0000         0,0000
film           0,2253         0,3108         0,4638         0,0000         0,0000         0,0000         0,0000
est            0,0975         0,1602         0,2675         0,4748         0,0000         0,0000         0,0000
excellent      0,0434         0,0854         0,1583         0,2903         0,4226         0,0000         0,0000
<END>          0,0283         0,0587         0,1119         0,2062         0,2964         0,2985         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             film           est            excellent      <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1482         0,1478         0,1530         0,1676         0,1873         0,1961         0,0000
le             0,1242         0,1317         0,1460         0,1734         0,2063         0,2184         0,0000
film           0,0974         0,1087         0,1309         0,1760         0,2346         0,2524         0,0000
est            0,0689         0,0789         0,1044         0,1688         0,2746         0,3044         0,0000
excellent      0,0508         0,0578         0,0818         0,1556         0,3055         0,3484         0,0000
<END>          0,0480         0,0542         0,0774         0,1520         0,3110         0,3574         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1392         0,1338         0,1378         0,1436         0,1473         0,1495         0,1489
je             0,1459         0,1415         0,1432         0,1434         0,1420         0,1417         0,1423
suis           0,1453         0,1437         0,1459         0,1439         0,1411         0,1397         0,1405
triste         0,1375         0,1404         0,1458         0,1452         0,1441         0,1431         0,1438
<UNK>          0,1273         0,1349         0,1441         0,1470         0,1486         0,1488         0,1493
<UNK>          0,1238         0,1321         0,1424         0,1477         0,1513         0,1518         0,1508
<UNK>          0,1278         0,1334         0,1416         0,1477         0,1512         0,1508         0,1475

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
je             0,4399         0,5601         0,0000         0,0000         0,0000         0,0000         0,0000
suis           0,2253         0,3096         0,4650         0,0000         0,0000         0,0000         0,0000
triste         0,0962         0,1573         0,2652         0,4812         0,0000         0,0000         0,0000
<END>          0,0437         0,0848         0,1577         0,2936         0,4203         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        je             suis           triste         <UNK>          <UNK>          <UNK>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1268         0,1252         0,1277         0,1420         0,1564         0,1653         0,1566
je             0,1060         0,1113         0,1217         0,1455         0,1697         0,1814         0,1644
suis           0,0829         0,0912         0,1082         0,1462         0,1909         0,2084         0,1722
triste         0,0583         0,0657         0,0856         0,1394         0,2216         0,2519         0,1774
<END>          0,0434         0,0487         0,0679         0,1291         0,2446         0,2888         0,1775
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.486043
===== Échantillon 1 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1650         0,1608         0,1633         0,1666         0,1698         0,1745         0,0000
ce             0,1713         0,1681         0,1686         0,1651         0,1627         0,1641         0,0000
temps          0,1699         0,1700         0,1716         0,1658         0,1615         0,1612         0,0000
est            0,1615         0,1669         0,1723         0,1684         0,1657         0,1652         0,0000
agréable       0,1506         0,1602         0,1703         0,1718         0,1732         0,1739         0,0000
<END>          0,1470         0,1572         0,1687         0,1731         0,1766         0,1774         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        le             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
le             0,4435         0,5565         0,0000         0,0000         0,0000         0,0000         0,0000
temps          0,2270         0,3083         0,4648         0,0000         0,0000         0,0000         0,0000
est            0,0955         0,1559         0,2648         0,4838         0,0000         0,0000         0,0000
agréable       0,0407         0,0803         0,1526         0,2890         0,4375         0,0000         0,0000
<END>          0,0259         0,0543         0,1066         0,2031         0,3041         0,3059         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        ce             temps          est            agréable       <END>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1509         0,1514         0,1555         0,1684         0,1823         0,1914         0,0000
le             0,1255         0,1342         0,1483         0,1748         0,2024         0,2148         0,0000
temps          0,0973         0,1099         0,1325         0,1778         0,2318         0,2507         0,0000
est            0,0678         0,0787         0,1049         0,1705         0,2723         0,3057         0,0000
agréable       0,0496         0,0574         0,0820         0,1571         0,3020         0,3519         0,0000
<END>          0,0465         0,0532         0,0768         0,1528         0,3079         0,3629         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Échantillon 2 =====
===== Encoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1987         0,1944         0,1968         0,2025         0,2075         0,0000         0,0000
quelle         0,2048         0,2018         0,2001         0,1978         0,1955         0,0000         0,0000
belle          0,2018         0,2042         0,2037         0,1982         0,1921         0,0000         0,0000
journée        0,1921         0,2004         0,2054         0,2033         0,1988         0,0000         0,0000
<END>          0,1816         0,1944         0,2055         0,2096         0,2089         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Self-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          <END>          <PAD>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        1,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000
quelle         0,4484         0,5516         0,0000         0,0000         0,0000         0,0000         0,0000
belle          0,2294         0,3080         0,4627         0,0000         0,0000         0,0000         0,0000
<END>          0,0958         0,1564         0,2677         0,4801         0,0000         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

===== Decoder Layer 1 Cross-Attention Weights =====
===== Tête 1 =====
Requête        <START>        quelle         belle          journée        <END>          <PAD>          <PAD>
------------------------------------------------------------------------------------------------------------------------
<START>        0,1830         0,1849         0,1929         0,2112         0,2280         0,0000         0,0000
quelle         0,1589         0,1700         0,1903         0,2250         0,2558         0,0000         0,0000
belle          0,1272         0,1431         0,1769         0,2418         0,3110         0,0000         0,0000
<END>          0,0943         0,1088         0,1506         0,2522         0,3942         0,0000         0,0000
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         
<PAD>          0,0000         0,0000         0,0000         0,0000         0,0000         0,0000         0,0000

Perte pour ce batch: 2.3669577
Epoch 10 completed with average loss: 0.013928342
Epoch 10 Loss: 0.013928342
